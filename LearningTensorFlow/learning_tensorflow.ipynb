{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import mnist library from tensorflow library\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot = True)\n",
    "\n",
    "# load data \n",
    "X_train = mnist.train.images\n",
    "Y_train = mnist.train.labels\n",
    "\n",
    "X_test = mnist.test.images\n",
    "Y_test = mnist.test.labels\n",
    "\n",
    "batch_X, batch_Y = mnist.train.next_batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple hello world program\n",
    "import tensorflow as tf\n",
    "hello = tf.constant(\"Hello, World!\")\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# basic operations with constants\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(3)\n",
    "b = tf.constant(5)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print \"Addition with constants: %i\" % sess.run(a+b)\n",
    "    print \"Multiplication with constants: %i \" % sess.run(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# basic operations with variables\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.placeholder(tf.int16)\n",
    "b = tf.placeholder(tf.int16)\n",
    "\n",
    "add = tf.add(a, b)\n",
    "mul = tf.multiply(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print \"Addition with variables %i\" % sess.run(add, feed_dict = {a : 3, b : 5})\n",
    "    print \"Multiplication with variables %i\" % sess.run(mul, feed_dict = {a : 3, b : 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# basic operations with matrices\n",
    "import tensorflow as tf\n",
    "\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "matrix2 = tf.constant([[5.], [5.]])\n",
    "\n",
    "mul = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print \"Matrix multiplication %i\" % sess.run(mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nearest neighbors\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "## import mnist data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot = True)\n",
    "\n",
    "## creating training data\n",
    "X_tr, Y_tr = mnist.train.next_batch(5000)\n",
    "## creating test data\n",
    "X_te, Y_te = mnist.test.next_batch(200)\n",
    "\n",
    "## creating placeholders\n",
    "xtr = tf.placeholder(\"float\", [None, 784])\n",
    "xte = tf.placeholder(\"float\", 784)\n",
    "\n",
    "## L1 distance\n",
    "distance = tf.reduce_sum(tf.abs(tf.add(xtr, tf.negative(xte))), reduction_indices = 1)\n",
    "\n",
    "pred = tf.arg_min(distance, 0)\n",
    "accuracy  = 0.\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(len(X_te)):\n",
    "        nn_index = sess.run(pred, feed_dict = {xtr : X_tr, xte : X_te[i, :]})\n",
    "        print \"Test \", i, \"Prediction: \", np.argmax(Y_tr[nn_index]), \"True Class: \", np.argmax(Y_te[i])\n",
    "        if np.argmax(Y_tr[nn_index]) == np.argmax(Y_te[i]):\n",
    "            accuracy += 1./len(X_te)\n",
    "    print \"Accuracy: \", accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# linear regression\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = numpy.random\n",
    "\n",
    "## parametes\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "display_step = 50\n",
    "\n",
    "## training data\n",
    "train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "## placeholders\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "## coefficients for the linear equation\n",
    "W = tf.Variable(rng.random(), name = \"weight\")\n",
    "b = tf.Variable(rng.random(), name = \"bias\")\n",
    "\n",
    "## linear model\n",
    "pred = tf.add(tf.multiply(X, W), b)\n",
    "## mean square error\n",
    "cost = tf.reduce_sum(tf.pow(pred - Y, 2))/(2 * n_samples)\n",
    "\n",
    "## gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        for (x, y) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, feed_dict = {X : x, Y : y})\n",
    "            \n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict = {X : x, Y : y})\n",
    "            print \"Epoch: \", (epoch + 1), \"cost: \", c, \"weight: \", sess.run(W), \"bias: \", sess.run(b)\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)\n",
    "\n",
    "## parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "## training data\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "## weights and biases\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "## model\n",
    "pred = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "## cost function\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred), reduction_indices = 1))\n",
    "## gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict = {X : batch_xs, y: batch_ys})\n",
    "            avg_cost += c/batch_size\n",
    "        print \"Epoch: \", epoch, \"Cost: \", c\n",
    "        \n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print \"Accuracy\", accuracy.eval({X : mnist.test.images, y : mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# multilayer perceptron\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)\n",
    "\n",
    "## parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "## network parameters\n",
    "n_hl_1 = 256\n",
    "n_hl_2 = 256\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "## weights \n",
    "weights = {\n",
    "    'h1' : tf.Variable(tf.random_normal([n_input, n_hl_1])),\n",
    "    'h2' : tf.Variable(tf.random_normal([n_hl_1, n_hl_2])),\n",
    "    'out' : tf.Variable(tf.random_normal([n_hl_2, n_classes]))\n",
    "}\n",
    "\n",
    "## biases\n",
    "biases = {\n",
    "    'b1' : tf.Variable(tf.random_normal([n_hl_1])),\n",
    "    'b2' : tf.Variable(tf.random_normal([n_hl_2])),\n",
    "    'out' : tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "## MLP\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    hl1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    hl1 = tf.nn.relu(hl1)\n",
    "    \n",
    "    hl2 = tf.add(tf.matmul(hl1, weights['h2']), biases['b2'])\n",
    "    hl2 = tf.nn.relu(hl2)\n",
    "    \n",
    "    out_layer = tf.matmul(hl2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "## model\n",
    "pred = multilayer_perceptron(X, weights, biases)\n",
    "\n",
    "## cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))\n",
    "## optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size) \n",
    "            _, c = sess.run([optimizer, cost], feed_dict = {X : batch_x, y: batch_y})\n",
    "            avg_cost += c/total_batch\n",
    "        print \"Epoch: \", epoch, \"Cost: \", c\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    print \"Accuracy: \", accuracy.eval({X : mnist.test.images, y : mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "1\n",
      "Iter 128, Minibatch Loss= 63693.835938, Training Accuracy= 0.14844\n",
      "2\n",
      "Iter 256, Minibatch Loss= 42325.093750, Training Accuracy= 0.14844\n",
      "3\n",
      "Iter 384, Minibatch Loss= 34334.757812, Training Accuracy= 0.09375\n",
      "4\n",
      "Iter 512, Minibatch Loss= 22935.992188, Training Accuracy= 0.16406\n",
      "5\n",
      "Iter 640, Minibatch Loss= 25606.617188, Training Accuracy= 0.09375\n",
      "6\n",
      "Iter 768, Minibatch Loss= 28126.500000, Training Accuracy= 0.14844\n",
      "7\n",
      "Iter 896, Minibatch Loss= 33322.734375, Training Accuracy= 0.09375\n",
      "8\n",
      "Iter 1024, Minibatch Loss= 31564.152344, Training Accuracy= 0.12500\n",
      "9\n",
      "Iter 1152, Minibatch Loss= 31607.201172, Training Accuracy= 0.12500\n",
      "10\n",
      "Iter 1280, Minibatch Loss= 30712.810547, Training Accuracy= 0.10156\n",
      "11\n",
      "Iter 1408, Minibatch Loss= 24786.451172, Training Accuracy= 0.15625\n",
      "12\n",
      "Iter 1536, Minibatch Loss= 19328.726562, Training Accuracy= 0.21094\n",
      "13\n",
      "Iter 1664, Minibatch Loss= 13709.015625, Training Accuracy= 0.32812\n",
      "14\n",
      "Iter 1792, Minibatch Loss= 16264.131836, Training Accuracy= 0.27344\n",
      "15\n",
      "Iter 1920, Minibatch Loss= 11416.269531, Training Accuracy= 0.32812\n",
      "16\n",
      "Iter 2048, Minibatch Loss= 9424.445312, Training Accuracy= 0.44531\n",
      "17\n",
      "Iter 2176, Minibatch Loss= 12274.925781, Training Accuracy= 0.39844\n",
      "18\n",
      "Iter 2304, Minibatch Loss= 11504.974609, Training Accuracy= 0.35156\n",
      "19\n",
      "Iter 2432, Minibatch Loss= 10159.143555, Training Accuracy= 0.38281\n",
      "20\n",
      "Iter 2560, Minibatch Loss= 8622.566406, Training Accuracy= 0.45312\n",
      "21\n",
      "Iter 2688, Minibatch Loss= 10602.321289, Training Accuracy= 0.43750\n",
      "22\n",
      "Iter 2816, Minibatch Loss= 12470.998047, Training Accuracy= 0.46094\n",
      "23\n",
      "Iter 2944, Minibatch Loss= 11049.273438, Training Accuracy= 0.50000\n",
      "24\n",
      "Iter 3072, Minibatch Loss= 10579.876953, Training Accuracy= 0.47656\n",
      "25\n",
      "Iter 3200, Minibatch Loss= 9652.555664, Training Accuracy= 0.51562\n",
      "26\n",
      "Iter 3328, Minibatch Loss= 11127.156250, Training Accuracy= 0.49219\n",
      "27\n",
      "Iter 3456, Minibatch Loss= 7378.538086, Training Accuracy= 0.57812\n",
      "28\n",
      "Iter 3584, Minibatch Loss= 7152.875977, Training Accuracy= 0.61719\n",
      "29\n",
      "Iter 3712, Minibatch Loss= 8718.205078, Training Accuracy= 0.54688\n",
      "30\n",
      "Iter 3840, Minibatch Loss= 9423.623047, Training Accuracy= 0.47656\n",
      "31\n",
      "Iter 3968, Minibatch Loss= 8432.208008, Training Accuracy= 0.51562\n",
      "32\n",
      "Iter 4096, Minibatch Loss= 5009.138184, Training Accuracy= 0.70312\n",
      "33\n",
      "Iter 4224, Minibatch Loss= 5643.580078, Training Accuracy= 0.69531\n",
      "34\n",
      "Iter 4352, Minibatch Loss= 4913.274902, Training Accuracy= 0.67969\n",
      "35\n",
      "Iter 4480, Minibatch Loss= 6542.458496, Training Accuracy= 0.64844\n",
      "36\n",
      "Iter 4608, Minibatch Loss= 6410.691895, Training Accuracy= 0.59375\n",
      "37\n",
      "Iter 4736, Minibatch Loss= 3274.295898, Training Accuracy= 0.72656\n",
      "38\n",
      "Iter 4864, Minibatch Loss= 4948.568359, Training Accuracy= 0.68750\n",
      "39\n",
      "Iter 4992, Minibatch Loss= 3794.356934, Training Accuracy= 0.70312\n",
      "40\n",
      "Iter 5120, Minibatch Loss= 4371.312012, Training Accuracy= 0.75781\n",
      "41\n",
      "Iter 5248, Minibatch Loss= 3932.137939, Training Accuracy= 0.70312\n",
      "42\n",
      "Iter 5376, Minibatch Loss= 4100.358398, Training Accuracy= 0.75000\n",
      "43\n",
      "Iter 5504, Minibatch Loss= 2141.903809, Training Accuracy= 0.80469\n",
      "44\n",
      "Iter 5632, Minibatch Loss= 3869.511963, Training Accuracy= 0.74219\n",
      "45\n",
      "Iter 5760, Minibatch Loss= 4157.761719, Training Accuracy= 0.75000\n",
      "46\n",
      "Iter 5888, Minibatch Loss= 2239.827148, Training Accuracy= 0.80469\n",
      "47\n",
      "Iter 6016, Minibatch Loss= 2315.896484, Training Accuracy= 0.80469\n",
      "48\n",
      "Iter 6144, Minibatch Loss= 2628.095459, Training Accuracy= 0.79688\n",
      "49\n",
      "Iter 6272, Minibatch Loss= 5477.424316, Training Accuracy= 0.70312\n",
      "50\n",
      "Iter 6400, Minibatch Loss= 3265.148438, Training Accuracy= 0.78125\n",
      "51\n",
      "Iter 6528, Minibatch Loss= 3305.919922, Training Accuracy= 0.75000\n",
      "52\n",
      "Iter 6656, Minibatch Loss= 5105.377441, Training Accuracy= 0.72656\n",
      "53\n",
      "Iter 6784, Minibatch Loss= 5398.865723, Training Accuracy= 0.71094\n",
      "54\n",
      "Iter 6912, Minibatch Loss= 4628.162109, Training Accuracy= 0.64844\n",
      "55\n",
      "Iter 7040, Minibatch Loss= 3414.336426, Training Accuracy= 0.75000\n",
      "56\n",
      "Iter 7168, Minibatch Loss= 3465.942871, Training Accuracy= 0.78906\n",
      "57\n",
      "Iter 7296, Minibatch Loss= 4691.020996, Training Accuracy= 0.77344\n",
      "58\n",
      "Iter 7424, Minibatch Loss= 4336.084961, Training Accuracy= 0.75781\n",
      "59\n",
      "Iter 7552, Minibatch Loss= 4139.968750, Training Accuracy= 0.75781\n",
      "60\n",
      "Iter 7680, Minibatch Loss= 5993.788086, Training Accuracy= 0.70312\n",
      "61\n",
      "Iter 7808, Minibatch Loss= 3490.505615, Training Accuracy= 0.78906\n",
      "62\n",
      "Iter 7936, Minibatch Loss= 2848.704102, Training Accuracy= 0.79688\n",
      "63\n",
      "Iter 8064, Minibatch Loss= 5906.244141, Training Accuracy= 0.62500\n",
      "64\n",
      "Iter 8192, Minibatch Loss= 4097.251953, Training Accuracy= 0.71094\n",
      "65\n",
      "Iter 8320, Minibatch Loss= 1705.768555, Training Accuracy= 0.84375\n",
      "66\n",
      "Iter 8448, Minibatch Loss= 2297.031006, Training Accuracy= 0.81250\n",
      "67\n",
      "Iter 8576, Minibatch Loss= 1976.889160, Training Accuracy= 0.86719\n",
      "68\n",
      "Iter 8704, Minibatch Loss= 2321.350098, Training Accuracy= 0.85938\n",
      "69\n",
      "Iter 8832, Minibatch Loss= 2325.654785, Training Accuracy= 0.82812\n",
      "70\n",
      "Iter 8960, Minibatch Loss= 2877.959961, Training Accuracy= 0.75781\n",
      "71\n",
      "Iter 9088, Minibatch Loss= 3341.261963, Training Accuracy= 0.72656\n",
      "72\n",
      "Iter 9216, Minibatch Loss= 5309.245117, Training Accuracy= 0.74219\n",
      "73\n",
      "Iter 9344, Minibatch Loss= 3929.954590, Training Accuracy= 0.78125\n",
      "74\n",
      "Iter 9472, Minibatch Loss= 2377.474609, Training Accuracy= 0.85156\n",
      "75\n",
      "Iter 9600, Minibatch Loss= 4132.297363, Training Accuracy= 0.78906\n",
      "76\n",
      "Iter 9728, Minibatch Loss= 6045.069336, Training Accuracy= 0.60938\n",
      "77\n",
      "Iter 9856, Minibatch Loss= 5648.643555, Training Accuracy= 0.63281\n",
      "78\n",
      "Iter 9984, Minibatch Loss= 1618.019897, Training Accuracy= 0.85938\n",
      "79\n",
      "Iter 10112, Minibatch Loss= 3678.759521, Training Accuracy= 0.83594\n",
      "80\n",
      "Iter 10240, Minibatch Loss= 3489.400879, Training Accuracy= 0.78125\n",
      "81\n",
      "Iter 10368, Minibatch Loss= 2095.680176, Training Accuracy= 0.89062\n",
      "82\n",
      "Iter 10496, Minibatch Loss= 1704.798828, Training Accuracy= 0.86719\n",
      "83\n",
      "Iter 10624, Minibatch Loss= 2177.651367, Training Accuracy= 0.82031\n",
      "84\n",
      "Iter 10752, Minibatch Loss= 2765.692627, Training Accuracy= 0.81250\n",
      "85\n",
      "Iter 10880, Minibatch Loss= 3165.204102, Training Accuracy= 0.75000\n",
      "86\n",
      "Iter 11008, Minibatch Loss= 1191.247803, Training Accuracy= 0.87500\n",
      "87\n",
      "Iter 11136, Minibatch Loss= 2291.117920, Training Accuracy= 0.83594\n",
      "88\n",
      "Iter 11264, Minibatch Loss= 2153.564453, Training Accuracy= 0.85156\n",
      "89\n",
      "Iter 11392, Minibatch Loss= 2350.452148, Training Accuracy= 0.82812\n",
      "90\n",
      "Iter 11520, Minibatch Loss= 1272.293823, Training Accuracy= 0.92969\n",
      "91\n",
      "Iter 11648, Minibatch Loss= 1614.939575, Training Accuracy= 0.89844\n",
      "92\n",
      "Iter 11776, Minibatch Loss= 2231.074951, Training Accuracy= 0.90625\n",
      "93\n",
      "Iter 11904, Minibatch Loss= 2908.550781, Training Accuracy= 0.81250\n",
      "94\n",
      "Iter 12032, Minibatch Loss= 2548.042969, Training Accuracy= 0.82812\n",
      "95\n",
      "Iter 12160, Minibatch Loss= 2176.687256, Training Accuracy= 0.82812\n",
      "96\n",
      "Iter 12288, Minibatch Loss= 2452.022949, Training Accuracy= 0.84375\n",
      "97\n",
      "Iter 12416, Minibatch Loss= 1553.958008, Training Accuracy= 0.88281\n",
      "98\n",
      "Iter 12544, Minibatch Loss= 2507.859863, Training Accuracy= 0.83594\n",
      "99\n",
      "Iter 12672, Minibatch Loss= 2054.827637, Training Accuracy= 0.83594\n",
      "100\n",
      "Iter 12800, Minibatch Loss= 3095.746338, Training Accuracy= 0.80469\n",
      "101\n",
      "Iter 12928, Minibatch Loss= 2347.800537, Training Accuracy= 0.78906\n",
      "102\n",
      "Iter 13056, Minibatch Loss= 1269.531006, Training Accuracy= 0.90625\n",
      "103\n",
      "Iter 13184, Minibatch Loss= 1110.078613, Training Accuracy= 0.91406\n",
      "104\n",
      "Iter 13312, Minibatch Loss= 850.741577, Training Accuracy= 0.89062\n",
      "105\n",
      "Iter 13440, Minibatch Loss= 3201.497070, Training Accuracy= 0.76562\n",
      "106\n",
      "Iter 13568, Minibatch Loss= 1710.215698, Training Accuracy= 0.89062\n",
      "107\n",
      "Iter 13696, Minibatch Loss= 2768.927979, Training Accuracy= 0.87500\n",
      "108\n",
      "Iter 13824, Minibatch Loss= 1646.991333, Training Accuracy= 0.89062\n",
      "109\n",
      "Iter 13952, Minibatch Loss= 1490.682983, Training Accuracy= 0.89062\n",
      "110\n",
      "Iter 14080, Minibatch Loss= 1007.093262, Training Accuracy= 0.89062\n",
      "111\n",
      "Iter 14208, Minibatch Loss= 1983.894897, Training Accuracy= 0.85938\n",
      "112\n",
      "Iter 14336, Minibatch Loss= 1834.138550, Training Accuracy= 0.89844\n",
      "113\n",
      "Iter 14464, Minibatch Loss= 1786.611816, Training Accuracy= 0.86719\n",
      "114\n",
      "Iter 14592, Minibatch Loss= 1810.041260, Training Accuracy= 0.86719\n",
      "115\n",
      "Iter 14720, Minibatch Loss= 497.197021, Training Accuracy= 0.96875\n",
      "116\n",
      "Iter 14848, Minibatch Loss= 1713.142334, Training Accuracy= 0.92969\n",
      "117\n",
      "Iter 14976, Minibatch Loss= 2144.289062, Training Accuracy= 0.85156\n",
      "118\n",
      "Iter 15104, Minibatch Loss= 2470.604980, Training Accuracy= 0.86719\n",
      "119\n",
      "Iter 15232, Minibatch Loss= 1892.062500, Training Accuracy= 0.89062\n",
      "120\n",
      "Iter 15360, Minibatch Loss= 1569.162598, Training Accuracy= 0.92188\n",
      "121\n",
      "Iter 15488, Minibatch Loss= 1614.338867, Training Accuracy= 0.89062\n",
      "122\n",
      "Iter 15616, Minibatch Loss= 906.096313, Training Accuracy= 0.92969\n",
      "123\n",
      "Iter 15744, Minibatch Loss= 2469.918213, Training Accuracy= 0.86719\n",
      "124\n",
      "Iter 15872, Minibatch Loss= 3229.391602, Training Accuracy= 0.84375\n",
      "125\n",
      "Iter 16000, Minibatch Loss= 1793.578735, Training Accuracy= 0.87500\n",
      "126\n",
      "Iter 16128, Minibatch Loss= 1723.859253, Training Accuracy= 0.89844\n",
      "127\n",
      "Iter 16256, Minibatch Loss= 1307.460327, Training Accuracy= 0.90625\n",
      "128\n",
      "Iter 16384, Minibatch Loss= 1481.147949, Training Accuracy= 0.89844\n",
      "129\n",
      "Iter 16512, Minibatch Loss= 1545.817139, Training Accuracy= 0.87500\n",
      "130\n",
      "Iter 16640, Minibatch Loss= 1899.588501, Training Accuracy= 0.89062\n",
      "131\n",
      "Iter 16768, Minibatch Loss= 1107.905029, Training Accuracy= 0.89062\n",
      "132\n",
      "Iter 16896, Minibatch Loss= 934.333008, Training Accuracy= 0.90625\n",
      "133\n",
      "Iter 17024, Minibatch Loss= 912.382080, Training Accuracy= 0.94531\n",
      "134\n",
      "Iter 17152, Minibatch Loss= 1935.401367, Training Accuracy= 0.85938\n",
      "135\n",
      "Iter 17280, Minibatch Loss= 2671.508545, Training Accuracy= 0.83594\n",
      "136\n",
      "Iter 17408, Minibatch Loss= 909.592529, Training Accuracy= 0.92969\n",
      "137\n",
      "Iter 17536, Minibatch Loss= 2344.561279, Training Accuracy= 0.78906\n",
      "138\n",
      "Iter 17664, Minibatch Loss= 3068.795654, Training Accuracy= 0.84375\n",
      "139\n",
      "Iter 17792, Minibatch Loss= 1431.446899, Training Accuracy= 0.90625\n",
      "140\n",
      "Iter 17920, Minibatch Loss= 1095.425415, Training Accuracy= 0.92188\n",
      "141\n",
      "Iter 18048, Minibatch Loss= 825.031982, Training Accuracy= 0.90625\n",
      "142\n",
      "Iter 18176, Minibatch Loss= 1281.856567, Training Accuracy= 0.88281\n",
      "143\n",
      "Iter 18304, Minibatch Loss= 1269.255127, Training Accuracy= 0.92969\n",
      "144\n",
      "Iter 18432, Minibatch Loss= 878.942017, Training Accuracy= 0.92188\n",
      "145\n",
      "Iter 18560, Minibatch Loss= 1519.047363, Training Accuracy= 0.86719\n",
      "146\n",
      "Iter 18688, Minibatch Loss= 1036.873779, Training Accuracy= 0.91406\n",
      "147\n",
      "Iter 18816, Minibatch Loss= 1450.156616, Training Accuracy= 0.87500\n",
      "148\n",
      "Iter 18944, Minibatch Loss= 1788.847168, Training Accuracy= 0.89062\n",
      "149\n",
      "Iter 19072, Minibatch Loss= 1681.329346, Training Accuracy= 0.88281\n",
      "150\n",
      "Iter 19200, Minibatch Loss= 1128.628784, Training Accuracy= 0.90625\n",
      "151\n",
      "Iter 19328, Minibatch Loss= 1361.376465, Training Accuracy= 0.87500\n",
      "152\n",
      "Iter 19456, Minibatch Loss= 730.922729, Training Accuracy= 0.93750\n",
      "153\n",
      "Iter 19584, Minibatch Loss= 1426.058105, Training Accuracy= 0.88281\n",
      "154\n",
      "Iter 19712, Minibatch Loss= 2009.404297, Training Accuracy= 0.85938\n",
      "155\n",
      "Iter 19840, Minibatch Loss= 1872.991089, Training Accuracy= 0.87500\n",
      "156\n",
      "Iter 19968, Minibatch Loss= 1705.344727, Training Accuracy= 0.88281\n",
      "157\n",
      "Iter 20096, Minibatch Loss= 1419.480347, Training Accuracy= 0.92188\n",
      "158\n",
      "Iter 20224, Minibatch Loss= 1293.275757, Training Accuracy= 0.89062\n",
      "159\n",
      "Iter 20352, Minibatch Loss= 1433.252197, Training Accuracy= 0.88281\n",
      "160\n",
      "Iter 20480, Minibatch Loss= 371.913300, Training Accuracy= 0.97656\n",
      "161\n",
      "Iter 20608, Minibatch Loss= 1978.388916, Training Accuracy= 0.90625\n",
      "162\n",
      "Iter 20736, Minibatch Loss= 1272.944336, Training Accuracy= 0.91406\n",
      "163\n",
      "Iter 20864, Minibatch Loss= 3001.265381, Training Accuracy= 0.86719\n",
      "164\n",
      "Iter 20992, Minibatch Loss= 1071.090942, Training Accuracy= 0.91406\n",
      "165\n",
      "Iter 21120, Minibatch Loss= 645.277954, Training Accuracy= 0.91406\n",
      "166\n",
      "Iter 21248, Minibatch Loss= 1081.439209, Training Accuracy= 0.91406\n",
      "167\n",
      "Iter 21376, Minibatch Loss= 1522.212402, Training Accuracy= 0.92188\n",
      "168\n",
      "Iter 21504, Minibatch Loss= 2203.079590, Training Accuracy= 0.86719\n",
      "169\n",
      "Iter 21632, Minibatch Loss= 1947.597412, Training Accuracy= 0.92188\n",
      "170\n",
      "Iter 21760, Minibatch Loss= 3691.282471, Training Accuracy= 0.79688\n",
      "171\n",
      "Iter 21888, Minibatch Loss= 2028.820679, Training Accuracy= 0.91406\n",
      "172\n",
      "Iter 22016, Minibatch Loss= 972.251038, Training Accuracy= 0.92969\n",
      "173\n",
      "Iter 22144, Minibatch Loss= 1023.013245, Training Accuracy= 0.90625\n",
      "174\n",
      "Iter 22272, Minibatch Loss= 2498.843262, Training Accuracy= 0.85156\n",
      "175\n",
      "Iter 22400, Minibatch Loss= 409.914459, Training Accuracy= 0.95312\n",
      "176\n",
      "Iter 22528, Minibatch Loss= 1391.185669, Training Accuracy= 0.88281\n",
      "177\n",
      "Iter 22656, Minibatch Loss= 1604.514526, Training Accuracy= 0.89844\n",
      "178\n",
      "Iter 22784, Minibatch Loss= 2055.240967, Training Accuracy= 0.90625\n",
      "179\n",
      "Iter 22912, Minibatch Loss= 1927.125244, Training Accuracy= 0.86719\n",
      "180\n",
      "Iter 23040, Minibatch Loss= 556.817139, Training Accuracy= 0.96875\n",
      "181\n",
      "Iter 23168, Minibatch Loss= 1215.093018, Training Accuracy= 0.89062\n",
      "182\n",
      "Iter 23296, Minibatch Loss= 1587.989990, Training Accuracy= 0.89062\n",
      "183\n",
      "Iter 23424, Minibatch Loss= 1956.427734, Training Accuracy= 0.88281\n",
      "184\n",
      "Iter 23552, Minibatch Loss= 570.907593, Training Accuracy= 0.95312\n",
      "185\n",
      "Iter 23680, Minibatch Loss= 2593.491699, Training Accuracy= 0.85156\n",
      "186\n",
      "Iter 23808, Minibatch Loss= 1237.078857, Training Accuracy= 0.88281\n",
      "187\n",
      "Iter 23936, Minibatch Loss= 601.520691, Training Accuracy= 0.92188\n",
      "188\n",
      "Iter 24064, Minibatch Loss= 1323.958008, Training Accuracy= 0.89062\n",
      "189\n",
      "Iter 24192, Minibatch Loss= 1527.179443, Training Accuracy= 0.89062\n",
      "190\n",
      "Iter 24320, Minibatch Loss= 1104.567993, Training Accuracy= 0.89844\n",
      "191\n",
      "Iter 24448, Minibatch Loss= 2421.464844, Training Accuracy= 0.86719\n",
      "192\n",
      "Iter 24576, Minibatch Loss= 1399.034912, Training Accuracy= 0.91406\n",
      "193\n",
      "Iter 24704, Minibatch Loss= 1074.167725, Training Accuracy= 0.92969\n",
      "194\n",
      "Iter 24832, Minibatch Loss= 1304.520142, Training Accuracy= 0.86719\n",
      "195\n",
      "Iter 24960, Minibatch Loss= 1652.775146, Training Accuracy= 0.86719\n",
      "196\n",
      "Iter 25088, Minibatch Loss= 1074.696411, Training Accuracy= 0.91406\n",
      "197\n",
      "Iter 25216, Minibatch Loss= 1208.574463, Training Accuracy= 0.90625\n",
      "198\n",
      "Iter 25344, Minibatch Loss= 729.616516, Training Accuracy= 0.94531\n",
      "199\n",
      "Iter 25472, Minibatch Loss= 1190.520752, Training Accuracy= 0.88281\n",
      "200\n",
      "Iter 25600, Minibatch Loss= 1275.919922, Training Accuracy= 0.90625\n",
      "201\n",
      "Iter 25728, Minibatch Loss= 1857.643433, Training Accuracy= 0.86719\n",
      "202\n",
      "Iter 25856, Minibatch Loss= 760.679321, Training Accuracy= 0.92188\n",
      "203\n",
      "Iter 25984, Minibatch Loss= 1008.004761, Training Accuracy= 0.92969\n",
      "204\n",
      "Iter 26112, Minibatch Loss= 1033.413208, Training Accuracy= 0.93750\n",
      "205\n",
      "Iter 26240, Minibatch Loss= 3055.791016, Training Accuracy= 0.90625\n",
      "206\n",
      "Iter 26368, Minibatch Loss= 2285.268555, Training Accuracy= 0.85938\n",
      "207\n",
      "Iter 26496, Minibatch Loss= 1570.006226, Training Accuracy= 0.87500\n",
      "208\n",
      "Iter 26624, Minibatch Loss= 732.912903, Training Accuracy= 0.93750\n",
      "209\n",
      "Iter 26752, Minibatch Loss= 3211.716797, Training Accuracy= 0.85938\n",
      "210\n",
      "Iter 26880, Minibatch Loss= 748.640991, Training Accuracy= 0.91406\n",
      "211\n",
      "Iter 27008, Minibatch Loss= 903.867249, Training Accuracy= 0.90625\n",
      "212\n",
      "Iter 27136, Minibatch Loss= 1757.435547, Training Accuracy= 0.88281\n",
      "213\n",
      "Iter 27264, Minibatch Loss= 598.474731, Training Accuracy= 0.91406\n",
      "214\n",
      "Iter 27392, Minibatch Loss= 1978.308350, Training Accuracy= 0.83594\n",
      "215\n",
      "Iter 27520, Minibatch Loss= 1972.566772, Training Accuracy= 0.87500\n",
      "216\n",
      "Iter 27648, Minibatch Loss= 315.304993, Training Accuracy= 0.96875\n",
      "217\n",
      "Iter 27776, Minibatch Loss= 597.490051, Training Accuracy= 0.97656\n",
      "218\n",
      "Iter 27904, Minibatch Loss= 1254.562866, Training Accuracy= 0.91406\n",
      "219\n",
      "Iter 28032, Minibatch Loss= 631.462708, Training Accuracy= 0.91406\n",
      "220\n",
      "Iter 28160, Minibatch Loss= 1205.715210, Training Accuracy= 0.91406\n",
      "221\n",
      "Iter 28288, Minibatch Loss= 1013.125183, Training Accuracy= 0.96094\n",
      "222\n",
      "Iter 28416, Minibatch Loss= 1632.012817, Training Accuracy= 0.89062\n",
      "223\n",
      "Iter 28544, Minibatch Loss= 1757.819336, Training Accuracy= 0.89844\n",
      "224\n",
      "Iter 28672, Minibatch Loss= 1001.437256, Training Accuracy= 0.93750\n",
      "225\n",
      "Iter 28800, Minibatch Loss= 1081.801270, Training Accuracy= 0.92188\n",
      "226\n",
      "Iter 28928, Minibatch Loss= 653.609741, Training Accuracy= 0.95312\n",
      "227\n",
      "Iter 29056, Minibatch Loss= 1181.598633, Training Accuracy= 0.93750\n",
      "228\n",
      "Iter 29184, Minibatch Loss= 295.942780, Training Accuracy= 0.97656\n",
      "229\n",
      "Iter 29312, Minibatch Loss= 577.473755, Training Accuracy= 0.94531\n",
      "230\n",
      "Iter 29440, Minibatch Loss= 1499.627686, Training Accuracy= 0.91406\n",
      "231\n",
      "Iter 29568, Minibatch Loss= 1959.820190, Training Accuracy= 0.87500\n",
      "232\n",
      "Iter 29696, Minibatch Loss= 1486.527344, Training Accuracy= 0.88281\n",
      "233\n",
      "Iter 29824, Minibatch Loss= 1830.447021, Training Accuracy= 0.88281\n",
      "234\n",
      "Iter 29952, Minibatch Loss= 2406.524414, Training Accuracy= 0.86719\n",
      "235\n",
      "Iter 30080, Minibatch Loss= 890.156067, Training Accuracy= 0.93750\n",
      "236\n",
      "Iter 30208, Minibatch Loss= 912.536377, Training Accuracy= 0.89844\n",
      "237\n",
      "Iter 30336, Minibatch Loss= 1004.727173, Training Accuracy= 0.94531\n",
      "238\n",
      "Iter 30464, Minibatch Loss= 512.975708, Training Accuracy= 0.95312\n",
      "239\n",
      "Iter 30592, Minibatch Loss= 1210.644043, Training Accuracy= 0.92188\n",
      "240\n",
      "Iter 30720, Minibatch Loss= 897.355469, Training Accuracy= 0.90625\n",
      "241\n",
      "Iter 30848, Minibatch Loss= 661.313110, Training Accuracy= 0.94531\n",
      "242\n",
      "Iter 30976, Minibatch Loss= 956.141052, Training Accuracy= 0.91406\n",
      "243\n",
      "Iter 31104, Minibatch Loss= 1419.554810, Training Accuracy= 0.89844\n",
      "244\n",
      "Iter 31232, Minibatch Loss= 1135.142822, Training Accuracy= 0.92969\n",
      "245\n",
      "Iter 31360, Minibatch Loss= 185.269089, Training Accuracy= 0.97656\n",
      "246\n",
      "Iter 31488, Minibatch Loss= 1361.495850, Training Accuracy= 0.93750\n",
      "247\n",
      "Iter 31616, Minibatch Loss= 895.804932, Training Accuracy= 0.95312\n",
      "248\n",
      "Iter 31744, Minibatch Loss= 655.538330, Training Accuracy= 0.95312\n",
      "249\n",
      "Iter 31872, Minibatch Loss= 1441.170288, Training Accuracy= 0.92969\n",
      "250\n",
      "Iter 32000, Minibatch Loss= 1004.392090, Training Accuracy= 0.94531\n",
      "251\n",
      "Iter 32128, Minibatch Loss= 1444.151733, Training Accuracy= 0.90625\n",
      "252\n",
      "Iter 32256, Minibatch Loss= 761.812744, Training Accuracy= 0.92969\n",
      "253\n",
      "Iter 32384, Minibatch Loss= 2198.980957, Training Accuracy= 0.90625\n",
      "254\n",
      "Iter 32512, Minibatch Loss= 1936.064453, Training Accuracy= 0.86719\n",
      "255\n",
      "Iter 32640, Minibatch Loss= 1334.026123, Training Accuracy= 0.87500\n",
      "256\n",
      "Iter 32768, Minibatch Loss= 1042.740234, Training Accuracy= 0.92969\n",
      "257\n",
      "Iter 32896, Minibatch Loss= 1271.441895, Training Accuracy= 0.93750\n",
      "258\n",
      "Iter 33024, Minibatch Loss= 995.278442, Training Accuracy= 0.90625\n",
      "259\n",
      "Iter 33152, Minibatch Loss= 617.349182, Training Accuracy= 0.92969\n",
      "260\n",
      "Iter 33280, Minibatch Loss= 639.565735, Training Accuracy= 0.90625\n",
      "261\n",
      "Iter 33408, Minibatch Loss= 1213.260498, Training Accuracy= 0.89844\n",
      "262\n",
      "Iter 33536, Minibatch Loss= 585.276184, Training Accuracy= 0.93750\n",
      "263\n",
      "Iter 33664, Minibatch Loss= 1011.138245, Training Accuracy= 0.93750\n",
      "264\n",
      "Iter 33792, Minibatch Loss= 1239.273071, Training Accuracy= 0.89844\n",
      "265\n",
      "Iter 33920, Minibatch Loss= 266.834106, Training Accuracy= 0.96094\n",
      "266\n",
      "Iter 34048, Minibatch Loss= 866.599121, Training Accuracy= 0.92969\n",
      "267\n",
      "Iter 34176, Minibatch Loss= 124.811005, Training Accuracy= 0.97656\n",
      "268\n",
      "Iter 34304, Minibatch Loss= 1419.662109, Training Accuracy= 0.92969\n",
      "269\n",
      "Iter 34432, Minibatch Loss= 2471.008789, Training Accuracy= 0.88281\n",
      "270\n",
      "Iter 34560, Minibatch Loss= 317.789734, Training Accuracy= 0.95312\n",
      "271\n",
      "Iter 34688, Minibatch Loss= 1076.210327, Training Accuracy= 0.92969\n",
      "272\n",
      "Iter 34816, Minibatch Loss= 833.704712, Training Accuracy= 0.93750\n",
      "273\n",
      "Iter 34944, Minibatch Loss= 520.171692, Training Accuracy= 0.89062\n",
      "274\n",
      "Iter 35072, Minibatch Loss= 1079.944458, Training Accuracy= 0.92188\n",
      "275\n",
      "Iter 35200, Minibatch Loss= 457.070618, Training Accuracy= 0.92969\n",
      "276\n",
      "Iter 35328, Minibatch Loss= 595.148499, Training Accuracy= 0.93750\n",
      "277\n",
      "Iter 35456, Minibatch Loss= 435.050293, Training Accuracy= 0.96094\n",
      "278\n",
      "Iter 35584, Minibatch Loss= 884.465088, Training Accuracy= 0.94531\n",
      "279\n",
      "Iter 35712, Minibatch Loss= 979.406250, Training Accuracy= 0.92188\n",
      "280\n",
      "Iter 35840, Minibatch Loss= 741.294800, Training Accuracy= 0.94531\n",
      "281\n",
      "Iter 35968, Minibatch Loss= 1189.416138, Training Accuracy= 0.93750\n",
      "282\n",
      "Iter 36096, Minibatch Loss= 1161.881104, Training Accuracy= 0.90625\n",
      "283\n",
      "Iter 36224, Minibatch Loss= 816.071472, Training Accuracy= 0.94531\n",
      "284\n",
      "Iter 36352, Minibatch Loss= 2472.165039, Training Accuracy= 0.84375\n",
      "285\n",
      "Iter 36480, Minibatch Loss= 1869.162354, Training Accuracy= 0.90625\n",
      "286\n",
      "Iter 36608, Minibatch Loss= 1325.255493, Training Accuracy= 0.94531\n",
      "287\n",
      "Iter 36736, Minibatch Loss= 663.287842, Training Accuracy= 0.92969\n",
      "288\n",
      "Iter 36864, Minibatch Loss= 681.920410, Training Accuracy= 0.90625\n",
      "289\n",
      "Iter 36992, Minibatch Loss= 692.990906, Training Accuracy= 0.93750\n",
      "290\n",
      "Iter 37120, Minibatch Loss= 1324.358643, Training Accuracy= 0.91406\n",
      "291\n",
      "Iter 37248, Minibatch Loss= 857.989868, Training Accuracy= 0.92969\n",
      "292\n",
      "Iter 37376, Minibatch Loss= 1109.996826, Training Accuracy= 0.89844\n",
      "293\n",
      "Iter 37504, Minibatch Loss= 2868.432617, Training Accuracy= 0.88281\n",
      "294\n",
      "Iter 37632, Minibatch Loss= 2098.219238, Training Accuracy= 0.91406\n",
      "295\n",
      "Iter 37760, Minibatch Loss= 740.438904, Training Accuracy= 0.92969\n",
      "296\n",
      "Iter 37888, Minibatch Loss= 1052.799805, Training Accuracy= 0.90625\n",
      "297\n",
      "Iter 38016, Minibatch Loss= 1236.707520, Training Accuracy= 0.89062\n",
      "298\n",
      "Iter 38144, Minibatch Loss= 730.757935, Training Accuracy= 0.93750\n",
      "299\n",
      "Iter 38272, Minibatch Loss= 1265.312256, Training Accuracy= 0.91406\n",
      "300\n",
      "Iter 38400, Minibatch Loss= 92.707855, Training Accuracy= 0.99219\n",
      "301\n",
      "Iter 38528, Minibatch Loss= 490.049683, Training Accuracy= 0.95312\n",
      "302\n",
      "Iter 38656, Minibatch Loss= 262.166504, Training Accuracy= 0.97656\n",
      "303\n",
      "Iter 38784, Minibatch Loss= 788.888428, Training Accuracy= 0.93750\n",
      "304\n",
      "Iter 38912, Minibatch Loss= 1034.660889, Training Accuracy= 0.89844\n",
      "305\n",
      "Iter 39040, Minibatch Loss= 1104.088867, Training Accuracy= 0.92969\n",
      "306\n",
      "Iter 39168, Minibatch Loss= 494.773651, Training Accuracy= 0.95312\n",
      "307\n",
      "Iter 39296, Minibatch Loss= 1224.253174, Training Accuracy= 0.92969\n",
      "308\n",
      "Iter 39424, Minibatch Loss= 1171.208740, Training Accuracy= 0.92969\n",
      "309\n",
      "Iter 39552, Minibatch Loss= 1650.179565, Training Accuracy= 0.93750\n",
      "310\n",
      "Iter 39680, Minibatch Loss= 319.823608, Training Accuracy= 0.94531\n",
      "311\n",
      "Iter 39808, Minibatch Loss= 778.045715, Training Accuracy= 0.91406\n",
      "312\n",
      "Iter 39936, Minibatch Loss= 1241.452026, Training Accuracy= 0.92188\n",
      "313\n",
      "Iter 40064, Minibatch Loss= 1657.910522, Training Accuracy= 0.89844\n",
      "314\n",
      "Iter 40192, Minibatch Loss= 919.221619, Training Accuracy= 0.95312\n",
      "315\n",
      "Iter 40320, Minibatch Loss= 380.717163, Training Accuracy= 0.95312\n",
      "316\n",
      "Iter 40448, Minibatch Loss= 694.893860, Training Accuracy= 0.93750\n",
      "317\n",
      "Iter 40576, Minibatch Loss= 1149.414917, Training Accuracy= 0.92969\n",
      "318\n",
      "Iter 40704, Minibatch Loss= 999.824341, Training Accuracy= 0.89062\n",
      "319\n",
      "Iter 40832, Minibatch Loss= 865.361267, Training Accuracy= 0.95312\n",
      "320\n",
      "Iter 40960, Minibatch Loss= 1578.827637, Training Accuracy= 0.89844\n",
      "321\n",
      "Iter 41088, Minibatch Loss= 623.947144, Training Accuracy= 0.92188\n",
      "322\n",
      "Iter 41216, Minibatch Loss= 1071.603516, Training Accuracy= 0.95312\n",
      "323\n",
      "Iter 41344, Minibatch Loss= 1519.072144, Training Accuracy= 0.87500\n",
      "324\n",
      "Iter 41472, Minibatch Loss= 1459.306030, Training Accuracy= 0.89844\n",
      "325\n",
      "Iter 41600, Minibatch Loss= 496.485840, Training Accuracy= 0.93750\n",
      "326\n",
      "Iter 41728, Minibatch Loss= 578.212280, Training Accuracy= 0.94531\n",
      "327\n",
      "Iter 41856, Minibatch Loss= 322.585541, Training Accuracy= 0.96094\n",
      "328\n",
      "Iter 41984, Minibatch Loss= 531.454529, Training Accuracy= 0.95312\n",
      "329\n",
      "Iter 42112, Minibatch Loss= 538.057129, Training Accuracy= 0.92969\n",
      "330\n",
      "Iter 42240, Minibatch Loss= 667.576660, Training Accuracy= 0.92969\n",
      "331\n",
      "Iter 42368, Minibatch Loss= 981.996094, Training Accuracy= 0.89062\n",
      "332\n",
      "Iter 42496, Minibatch Loss= 1117.737915, Training Accuracy= 0.90625\n",
      "333\n",
      "Iter 42624, Minibatch Loss= 959.515076, Training Accuracy= 0.92188\n",
      "334\n",
      "Iter 42752, Minibatch Loss= 150.888260, Training Accuracy= 0.97656\n",
      "335\n",
      "Iter 42880, Minibatch Loss= 601.541443, Training Accuracy= 0.95312\n",
      "336\n",
      "Iter 43008, Minibatch Loss= 1249.949829, Training Accuracy= 0.90625\n",
      "337\n",
      "Iter 43136, Minibatch Loss= 883.496948, Training Accuracy= 0.92969\n",
      "338\n",
      "Iter 43264, Minibatch Loss= 722.057556, Training Accuracy= 0.95312\n",
      "339\n",
      "Iter 43392, Minibatch Loss= 1319.138306, Training Accuracy= 0.92969\n",
      "340\n",
      "Iter 43520, Minibatch Loss= 535.694336, Training Accuracy= 0.96094\n",
      "341\n",
      "Iter 43648, Minibatch Loss= 546.389160, Training Accuracy= 0.92188\n",
      "342\n",
      "Iter 43776, Minibatch Loss= 683.984070, Training Accuracy= 0.93750\n",
      "343\n",
      "Iter 43904, Minibatch Loss= 542.673706, Training Accuracy= 0.93750\n",
      "344\n",
      "Iter 44032, Minibatch Loss= 1402.972290, Training Accuracy= 0.89062\n",
      "345\n",
      "Iter 44160, Minibatch Loss= 945.234497, Training Accuracy= 0.91406\n",
      "346\n",
      "Iter 44288, Minibatch Loss= 704.044373, Training Accuracy= 0.90625\n",
      "347\n",
      "Iter 44416, Minibatch Loss= 614.557129, Training Accuracy= 0.95312\n",
      "348\n",
      "Iter 44544, Minibatch Loss= 1283.498535, Training Accuracy= 0.87500\n",
      "349\n",
      "Iter 44672, Minibatch Loss= 1718.344849, Training Accuracy= 0.89062\n",
      "350\n",
      "Iter 44800, Minibatch Loss= 527.217468, Training Accuracy= 0.94531\n",
      "351\n",
      "Iter 44928, Minibatch Loss= 1164.202759, Training Accuracy= 0.89844\n",
      "352\n",
      "Iter 45056, Minibatch Loss= 208.217667, Training Accuracy= 0.94531\n",
      "353\n",
      "Iter 45184, Minibatch Loss= 412.448730, Training Accuracy= 0.95312\n",
      "354\n",
      "Iter 45312, Minibatch Loss= 1431.671143, Training Accuracy= 0.92969\n",
      "355\n",
      "Iter 45440, Minibatch Loss= 2997.582764, Training Accuracy= 0.82812\n",
      "356\n",
      "Iter 45568, Minibatch Loss= 797.976807, Training Accuracy= 0.92969\n",
      "357\n",
      "Iter 45696, Minibatch Loss= 1368.167236, Training Accuracy= 0.95312\n",
      "358\n",
      "Iter 45824, Minibatch Loss= 523.790833, Training Accuracy= 0.95312\n",
      "359\n",
      "Iter 45952, Minibatch Loss= 432.630310, Training Accuracy= 0.92188\n",
      "360\n",
      "Iter 46080, Minibatch Loss= 161.963028, Training Accuracy= 0.98438\n",
      "361\n",
      "Iter 46208, Minibatch Loss= 715.183716, Training Accuracy= 0.95312\n",
      "362\n",
      "Iter 46336, Minibatch Loss= 935.420288, Training Accuracy= 0.92188\n",
      "363\n",
      "Iter 46464, Minibatch Loss= 357.554993, Training Accuracy= 0.95312\n",
      "364\n",
      "Iter 46592, Minibatch Loss= 705.182312, Training Accuracy= 0.95312\n",
      "365\n",
      "Iter 46720, Minibatch Loss= 668.924316, Training Accuracy= 0.95312\n",
      "366\n",
      "Iter 46848, Minibatch Loss= 466.860138, Training Accuracy= 0.96875\n",
      "367\n",
      "Iter 46976, Minibatch Loss= 655.049255, Training Accuracy= 0.94531\n",
      "368\n",
      "Iter 47104, Minibatch Loss= 1401.422607, Training Accuracy= 0.87500\n",
      "369\n",
      "Iter 47232, Minibatch Loss= 1329.369629, Training Accuracy= 0.91406\n",
      "370\n",
      "Iter 47360, Minibatch Loss= 936.950806, Training Accuracy= 0.95312\n",
      "371\n",
      "Iter 47488, Minibatch Loss= 770.474365, Training Accuracy= 0.95312\n",
      "372\n",
      "Iter 47616, Minibatch Loss= 32.982712, Training Accuracy= 0.98438\n",
      "373\n",
      "Iter 47744, Minibatch Loss= 1002.966309, Training Accuracy= 0.92969\n",
      "374\n",
      "Iter 47872, Minibatch Loss= 782.328247, Training Accuracy= 0.92188\n",
      "375\n",
      "Iter 48000, Minibatch Loss= 2541.819092, Training Accuracy= 0.85156\n",
      "376\n",
      "Iter 48128, Minibatch Loss= 613.963867, Training Accuracy= 0.91406\n",
      "377\n",
      "Iter 48256, Minibatch Loss= 1149.440186, Training Accuracy= 0.95312\n",
      "378\n",
      "Iter 48384, Minibatch Loss= 410.250854, Training Accuracy= 0.96094\n",
      "379\n",
      "Iter 48512, Minibatch Loss= 450.430023, Training Accuracy= 0.95312\n",
      "380\n",
      "Iter 48640, Minibatch Loss= 1249.917969, Training Accuracy= 0.92188\n",
      "381\n",
      "Iter 48768, Minibatch Loss= 450.738281, Training Accuracy= 0.94531\n",
      "382\n",
      "Iter 48896, Minibatch Loss= 1180.415039, Training Accuracy= 0.95312\n",
      "383\n",
      "Iter 49024, Minibatch Loss= 1613.545166, Training Accuracy= 0.89844\n",
      "384\n",
      "Iter 49152, Minibatch Loss= 614.893005, Training Accuracy= 0.92969\n",
      "385\n",
      "Iter 49280, Minibatch Loss= 534.627563, Training Accuracy= 0.94531\n",
      "386\n",
      "Iter 49408, Minibatch Loss= 546.434082, Training Accuracy= 0.96094\n",
      "387\n",
      "Iter 49536, Minibatch Loss= 761.584351, Training Accuracy= 0.92969\n",
      "388\n",
      "Iter 49664, Minibatch Loss= 574.824707, Training Accuracy= 0.94531\n",
      "389\n",
      "Iter 49792, Minibatch Loss= 103.529449, Training Accuracy= 0.97656\n",
      "390\n",
      "Iter 49920, Minibatch Loss= 502.200439, Training Accuracy= 0.92969\n",
      "391\n",
      "Iter 50048, Minibatch Loss= 500.878662, Training Accuracy= 0.93750\n",
      "392\n",
      "Iter 50176, Minibatch Loss= 327.520935, Training Accuracy= 0.96094\n",
      "393\n",
      "Iter 50304, Minibatch Loss= 239.277954, Training Accuracy= 0.96094\n",
      "394\n",
      "Iter 50432, Minibatch Loss= 573.146118, Training Accuracy= 0.93750\n",
      "395\n",
      "Iter 50560, Minibatch Loss= 1008.996094, Training Accuracy= 0.92188\n",
      "396\n",
      "Iter 50688, Minibatch Loss= 489.871063, Training Accuracy= 0.96875\n",
      "397\n",
      "Iter 50816, Minibatch Loss= 905.600098, Training Accuracy= 0.95312\n",
      "398\n",
      "Iter 50944, Minibatch Loss= 796.596191, Training Accuracy= 0.94531\n",
      "399\n",
      "Iter 51072, Minibatch Loss= 315.073181, Training Accuracy= 0.97656\n",
      "400\n",
      "Iter 51200, Minibatch Loss= 340.443420, Training Accuracy= 0.93750\n",
      "401\n",
      "Iter 51328, Minibatch Loss= 933.570435, Training Accuracy= 0.92969\n",
      "402\n",
      "Iter 51456, Minibatch Loss= 375.850739, Training Accuracy= 0.94531\n",
      "403\n",
      "Iter 51584, Minibatch Loss= 731.807800, Training Accuracy= 0.90625\n",
      "404\n",
      "Iter 51712, Minibatch Loss= 851.542664, Training Accuracy= 0.92969\n",
      "405\n",
      "Iter 51840, Minibatch Loss= 298.973297, Training Accuracy= 0.96875\n",
      "406\n",
      "Iter 51968, Minibatch Loss= 226.116425, Training Accuracy= 0.97656\n",
      "407\n",
      "Iter 52096, Minibatch Loss= 599.874268, Training Accuracy= 0.93750\n",
      "408\n",
      "Iter 52224, Minibatch Loss= 103.878281, Training Accuracy= 0.98438\n",
      "409\n",
      "Iter 52352, Minibatch Loss= 314.998749, Training Accuracy= 0.94531\n",
      "410\n",
      "Iter 52480, Minibatch Loss= 3.975388, Training Accuracy= 0.99219\n",
      "411\n",
      "Iter 52608, Minibatch Loss= 420.586365, Training Accuracy= 0.96094\n",
      "412\n",
      "Iter 52736, Minibatch Loss= 1169.729004, Training Accuracy= 0.91406\n",
      "413\n",
      "Iter 52864, Minibatch Loss= 335.376038, Training Accuracy= 0.94531\n",
      "414\n",
      "Iter 52992, Minibatch Loss= 200.054871, Training Accuracy= 0.96094\n",
      "415\n",
      "Iter 53120, Minibatch Loss= 441.817902, Training Accuracy= 0.95312\n",
      "416\n",
      "Iter 53248, Minibatch Loss= 77.827972, Training Accuracy= 0.99219\n",
      "417\n",
      "Iter 53376, Minibatch Loss= 140.550812, Training Accuracy= 0.98438\n",
      "418\n",
      "Iter 53504, Minibatch Loss= 725.280334, Training Accuracy= 0.92188\n",
      "419\n",
      "Iter 53632, Minibatch Loss= 175.146378, Training Accuracy= 0.96875\n",
      "420\n",
      "Iter 53760, Minibatch Loss= 433.656372, Training Accuracy= 0.97656\n",
      "421\n",
      "Iter 53888, Minibatch Loss= 591.757324, Training Accuracy= 0.96094\n",
      "422\n",
      "Iter 54016, Minibatch Loss= 93.395035, Training Accuracy= 0.99219\n",
      "423\n",
      "Iter 54144, Minibatch Loss= 28.152405, Training Accuracy= 0.98438\n",
      "424\n",
      "Iter 54272, Minibatch Loss= 40.510788, Training Accuracy= 0.98438\n",
      "425\n",
      "Iter 54400, Minibatch Loss= 1403.159912, Training Accuracy= 0.89844\n",
      "426\n",
      "Iter 54528, Minibatch Loss= 689.273132, Training Accuracy= 0.96094\n",
      "427\n",
      "Iter 54656, Minibatch Loss= 188.052933, Training Accuracy= 0.97656\n",
      "428\n",
      "Iter 54784, Minibatch Loss= 1682.734741, Training Accuracy= 0.92188\n",
      "429\n",
      "Iter 54912, Minibatch Loss= 68.614655, Training Accuracy= 0.99219\n",
      "430\n",
      "Iter 55040, Minibatch Loss= 784.211182, Training Accuracy= 0.94531\n",
      "431\n",
      "Iter 55168, Minibatch Loss= 902.026001, Training Accuracy= 0.91406\n",
      "432\n",
      "Iter 55296, Minibatch Loss= 874.910400, Training Accuracy= 0.93750\n",
      "433\n",
      "Iter 55424, Minibatch Loss= 574.833069, Training Accuracy= 0.93750\n",
      "434\n",
      "Iter 55552, Minibatch Loss= 456.546509, Training Accuracy= 0.96875\n",
      "435\n",
      "Iter 55680, Minibatch Loss= 655.511719, Training Accuracy= 0.93750\n",
      "436\n",
      "Iter 55808, Minibatch Loss= 847.778442, Training Accuracy= 0.92188\n",
      "437\n",
      "Iter 55936, Minibatch Loss= 720.369629, Training Accuracy= 0.96094\n",
      "438\n",
      "Iter 56064, Minibatch Loss= 559.854431, Training Accuracy= 0.96094\n",
      "439\n",
      "Iter 56192, Minibatch Loss= 263.032349, Training Accuracy= 0.97656\n",
      "440\n",
      "Iter 56320, Minibatch Loss= 362.670929, Training Accuracy= 0.95312\n",
      "441\n",
      "Iter 56448, Minibatch Loss= 943.135864, Training Accuracy= 0.91406\n",
      "442\n",
      "Iter 56576, Minibatch Loss= 304.696899, Training Accuracy= 0.96875\n",
      "443\n",
      "Iter 56704, Minibatch Loss= 349.340790, Training Accuracy= 0.92969\n",
      "444\n",
      "Iter 56832, Minibatch Loss= 447.532898, Training Accuracy= 0.96875\n",
      "445\n",
      "Iter 56960, Minibatch Loss= 550.717712, Training Accuracy= 0.93750\n",
      "446\n",
      "Iter 57088, Minibatch Loss= 693.299194, Training Accuracy= 0.92188\n",
      "447\n",
      "Iter 57216, Minibatch Loss= 1237.482300, Training Accuracy= 0.92188\n",
      "448\n",
      "Iter 57344, Minibatch Loss= 421.439636, Training Accuracy= 0.93750\n",
      "449\n",
      "Iter 57472, Minibatch Loss= 900.849060, Training Accuracy= 0.92969\n",
      "450\n",
      "Iter 57600, Minibatch Loss= 397.909424, Training Accuracy= 0.94531\n",
      "451\n",
      "Iter 57728, Minibatch Loss= 510.102356, Training Accuracy= 0.94531\n",
      "452\n",
      "Iter 57856, Minibatch Loss= 454.133911, Training Accuracy= 0.95312\n",
      "453\n",
      "Iter 57984, Minibatch Loss= 752.256348, Training Accuracy= 0.94531\n",
      "454\n",
      "Iter 58112, Minibatch Loss= 178.985443, Training Accuracy= 0.97656\n",
      "455\n",
      "Iter 58240, Minibatch Loss= 973.074951, Training Accuracy= 0.92188\n",
      "456\n",
      "Iter 58368, Minibatch Loss= 514.376892, Training Accuracy= 0.95312\n",
      "457\n",
      "Iter 58496, Minibatch Loss= 506.915039, Training Accuracy= 0.95312\n",
      "458\n",
      "Iter 58624, Minibatch Loss= 503.329407, Training Accuracy= 0.95312\n",
      "459\n",
      "Iter 58752, Minibatch Loss= 642.602539, Training Accuracy= 0.92188\n",
      "460\n",
      "Iter 58880, Minibatch Loss= 607.161743, Training Accuracy= 0.96094\n",
      "461\n",
      "Iter 59008, Minibatch Loss= 212.644135, Training Accuracy= 0.96094\n",
      "462\n",
      "Iter 59136, Minibatch Loss= 1109.216309, Training Accuracy= 0.95312\n",
      "463\n",
      "Iter 59264, Minibatch Loss= 454.296509, Training Accuracy= 0.96875\n",
      "464\n",
      "Iter 59392, Minibatch Loss= 587.244202, Training Accuracy= 0.92188\n",
      "465\n",
      "Iter 59520, Minibatch Loss= 978.406128, Training Accuracy= 0.93750\n",
      "466\n",
      "Iter 59648, Minibatch Loss= 531.107178, Training Accuracy= 0.95312\n",
      "467\n",
      "Iter 59776, Minibatch Loss= 556.860962, Training Accuracy= 0.96875\n",
      "468\n",
      "Iter 59904, Minibatch Loss= 506.514313, Training Accuracy= 0.94531\n",
      "469\n",
      "Iter 60032, Minibatch Loss= 583.465454, Training Accuracy= 0.96094\n",
      "470\n",
      "Iter 60160, Minibatch Loss= 241.069427, Training Accuracy= 0.96094\n",
      "471\n",
      "Iter 60288, Minibatch Loss= 51.192276, Training Accuracy= 0.99219\n",
      "472\n",
      "Iter 60416, Minibatch Loss= 621.932495, Training Accuracy= 0.97656\n",
      "473\n",
      "Iter 60544, Minibatch Loss= 200.395935, Training Accuracy= 0.96875\n",
      "474\n",
      "Iter 60672, Minibatch Loss= 374.569580, Training Accuracy= 0.94531\n",
      "475\n",
      "Iter 60800, Minibatch Loss= 444.997925, Training Accuracy= 0.96094\n",
      "476\n",
      "Iter 60928, Minibatch Loss= 547.978027, Training Accuracy= 0.93750\n",
      "477\n",
      "Iter 61056, Minibatch Loss= 344.379425, Training Accuracy= 0.96094\n",
      "478\n",
      "Iter 61184, Minibatch Loss= 666.639832, Training Accuracy= 0.93750\n",
      "479\n",
      "Iter 61312, Minibatch Loss= 315.138763, Training Accuracy= 0.96875\n",
      "480\n",
      "Iter 61440, Minibatch Loss= 485.485962, Training Accuracy= 0.93750\n",
      "481\n",
      "Iter 61568, Minibatch Loss= 604.777710, Training Accuracy= 0.95312\n",
      "482\n",
      "Iter 61696, Minibatch Loss= 363.605774, Training Accuracy= 0.96094\n",
      "483\n",
      "Iter 61824, Minibatch Loss= 120.321243, Training Accuracy= 0.97656\n",
      "484\n",
      "Iter 61952, Minibatch Loss= 145.521179, Training Accuracy= 0.98438\n",
      "485\n",
      "Iter 62080, Minibatch Loss= 1053.664917, Training Accuracy= 0.92969\n",
      "486\n",
      "Iter 62208, Minibatch Loss= 59.128082, Training Accuracy= 0.97656\n",
      "487\n",
      "Iter 62336, Minibatch Loss= 1032.923828, Training Accuracy= 0.96094\n",
      "488\n",
      "Iter 62464, Minibatch Loss= 1129.337402, Training Accuracy= 0.90625\n",
      "489\n",
      "Iter 62592, Minibatch Loss= 655.506470, Training Accuracy= 0.96875\n",
      "490\n",
      "Iter 62720, Minibatch Loss= 385.942261, Training Accuracy= 0.96094\n",
      "491\n",
      "Iter 62848, Minibatch Loss= 326.293823, Training Accuracy= 0.92188\n",
      "492\n",
      "Iter 62976, Minibatch Loss= 616.606567, Training Accuracy= 0.92188\n",
      "493\n",
      "Iter 63104, Minibatch Loss= 157.047745, Training Accuracy= 0.97656\n",
      "494\n",
      "Iter 63232, Minibatch Loss= 337.136230, Training Accuracy= 0.95312\n",
      "495\n",
      "Iter 63360, Minibatch Loss= 1307.361328, Training Accuracy= 0.90625\n",
      "496\n",
      "Iter 63488, Minibatch Loss= 95.050758, Training Accuracy= 0.96875\n",
      "497\n",
      "Iter 63616, Minibatch Loss= 155.402710, Training Accuracy= 0.96875\n",
      "498\n",
      "Iter 63744, Minibatch Loss= 448.544769, Training Accuracy= 0.96094\n",
      "499\n",
      "Iter 63872, Minibatch Loss= 227.309647, Training Accuracy= 0.97656\n",
      "500\n",
      "Iter 64000, Minibatch Loss= 349.746918, Training Accuracy= 0.95312\n",
      "501\n",
      "Iter 64128, Minibatch Loss= 0.622314, Training Accuracy= 0.99219\n",
      "502\n",
      "Iter 64256, Minibatch Loss= 713.717163, Training Accuracy= 0.92969\n",
      "503\n",
      "Iter 64384, Minibatch Loss= 575.533325, Training Accuracy= 0.91406\n",
      "504\n",
      "Iter 64512, Minibatch Loss= 556.789856, Training Accuracy= 0.95312\n",
      "505\n",
      "Iter 64640, Minibatch Loss= 817.789062, Training Accuracy= 0.92188\n",
      "506\n",
      "Iter 64768, Minibatch Loss= 294.768372, Training Accuracy= 0.97656\n",
      "507\n",
      "Iter 64896, Minibatch Loss= 943.480347, Training Accuracy= 0.92969\n",
      "508\n",
      "Iter 65024, Minibatch Loss= 218.435196, Training Accuracy= 0.96875\n",
      "509\n",
      "Iter 65152, Minibatch Loss= 588.411316, Training Accuracy= 0.94531\n",
      "510\n",
      "Iter 65280, Minibatch Loss= 107.218903, Training Accuracy= 0.96875\n",
      "511\n",
      "Iter 65408, Minibatch Loss= 1482.510010, Training Accuracy= 0.92969\n",
      "512\n",
      "Iter 65536, Minibatch Loss= 750.299927, Training Accuracy= 0.90625\n",
      "513\n",
      "Iter 65664, Minibatch Loss= 666.102905, Training Accuracy= 0.96094\n",
      "514\n",
      "Iter 65792, Minibatch Loss= 351.732300, Training Accuracy= 0.96875\n",
      "515\n",
      "Iter 65920, Minibatch Loss= 111.289352, Training Accuracy= 0.96094\n",
      "516\n",
      "Iter 66048, Minibatch Loss= 806.095825, Training Accuracy= 0.94531\n",
      "517\n",
      "Iter 66176, Minibatch Loss= 1206.835449, Training Accuracy= 0.92969\n",
      "518\n",
      "Iter 66304, Minibatch Loss= 229.909424, Training Accuracy= 0.95312\n",
      "519\n",
      "Iter 66432, Minibatch Loss= 478.899750, Training Accuracy= 0.95312\n",
      "520\n",
      "Iter 66560, Minibatch Loss= 272.042786, Training Accuracy= 0.95312\n",
      "521\n",
      "Iter 66688, Minibatch Loss= 427.136108, Training Accuracy= 0.97656\n",
      "522\n",
      "Iter 66816, Minibatch Loss= 474.716614, Training Accuracy= 0.92969\n",
      "523\n",
      "Iter 66944, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "524\n",
      "Iter 67072, Minibatch Loss= 228.036667, Training Accuracy= 0.96875\n",
      "525\n",
      "Iter 67200, Minibatch Loss= 389.016418, Training Accuracy= 0.96094\n",
      "526\n",
      "Iter 67328, Minibatch Loss= 330.256653, Training Accuracy= 0.96094\n",
      "527\n",
      "Iter 67456, Minibatch Loss= 533.751099, Training Accuracy= 0.95312\n",
      "528\n",
      "Iter 67584, Minibatch Loss= 289.398621, Training Accuracy= 0.97656\n",
      "529\n",
      "Iter 67712, Minibatch Loss= 515.879639, Training Accuracy= 0.95312\n",
      "530\n",
      "Iter 67840, Minibatch Loss= 123.113266, Training Accuracy= 0.96094\n",
      "531\n",
      "Iter 67968, Minibatch Loss= 472.085083, Training Accuracy= 0.96094\n",
      "532\n",
      "Iter 68096, Minibatch Loss= 693.686401, Training Accuracy= 0.92969\n",
      "533\n",
      "Iter 68224, Minibatch Loss= 695.671387, Training Accuracy= 0.95312\n",
      "534\n",
      "Iter 68352, Minibatch Loss= 468.892609, Training Accuracy= 0.97656\n",
      "535\n",
      "Iter 68480, Minibatch Loss= 748.040771, Training Accuracy= 0.92188\n",
      "536\n",
      "Iter 68608, Minibatch Loss= 534.765015, Training Accuracy= 0.95312\n",
      "537\n",
      "Iter 68736, Minibatch Loss= 691.730408, Training Accuracy= 0.95312\n",
      "538\n",
      "Iter 68864, Minibatch Loss= 1295.610107, Training Accuracy= 0.90625\n",
      "539\n",
      "Iter 68992, Minibatch Loss= 201.021103, Training Accuracy= 0.96094\n",
      "540\n",
      "Iter 69120, Minibatch Loss= 160.182693, Training Accuracy= 0.97656\n",
      "541\n",
      "Iter 69248, Minibatch Loss= 222.833023, Training Accuracy= 0.96875\n",
      "542\n",
      "Iter 69376, Minibatch Loss= 478.187622, Training Accuracy= 0.93750\n",
      "543\n",
      "Iter 69504, Minibatch Loss= 1057.729248, Training Accuracy= 0.91406\n",
      "544\n",
      "Iter 69632, Minibatch Loss= 203.168137, Training Accuracy= 0.96875\n",
      "545\n",
      "Iter 69760, Minibatch Loss= 888.935242, Training Accuracy= 0.93750\n",
      "546\n",
      "Iter 69888, Minibatch Loss= 572.255249, Training Accuracy= 0.96094\n",
      "547\n",
      "Iter 70016, Minibatch Loss= 475.298767, Training Accuracy= 0.95312\n",
      "548\n",
      "Iter 70144, Minibatch Loss= 459.692139, Training Accuracy= 0.96094\n",
      "549\n",
      "Iter 70272, Minibatch Loss= 635.105408, Training Accuracy= 0.92969\n",
      "550\n",
      "Iter 70400, Minibatch Loss= 318.988220, Training Accuracy= 0.95312\n",
      "551\n",
      "Iter 70528, Minibatch Loss= 632.476013, Training Accuracy= 0.94531\n",
      "552\n",
      "Iter 70656, Minibatch Loss= 552.881836, Training Accuracy= 0.96094\n",
      "553\n",
      "Iter 70784, Minibatch Loss= 328.561218, Training Accuracy= 0.96875\n",
      "554\n",
      "Iter 70912, Minibatch Loss= 807.111084, Training Accuracy= 0.92969\n",
      "555\n",
      "Iter 71040, Minibatch Loss= 267.486755, Training Accuracy= 0.95312\n",
      "556\n",
      "Iter 71168, Minibatch Loss= 593.127625, Training Accuracy= 0.91406\n",
      "557\n",
      "Iter 71296, Minibatch Loss= 156.509033, Training Accuracy= 0.96875\n",
      "558\n",
      "Iter 71424, Minibatch Loss= 357.315643, Training Accuracy= 0.95312\n",
      "559\n",
      "Iter 71552, Minibatch Loss= 966.180664, Training Accuracy= 0.92188\n",
      "560\n",
      "Iter 71680, Minibatch Loss= 625.656372, Training Accuracy= 0.96094\n",
      "561\n",
      "Iter 71808, Minibatch Loss= 100.067978, Training Accuracy= 0.97656\n",
      "562\n",
      "Iter 71936, Minibatch Loss= 478.875946, Training Accuracy= 0.94531\n",
      "563\n",
      "Iter 72064, Minibatch Loss= 383.578094, Training Accuracy= 0.94531\n",
      "564\n",
      "Iter 72192, Minibatch Loss= 1011.767700, Training Accuracy= 0.94531\n",
      "565\n",
      "Iter 72320, Minibatch Loss= 594.994263, Training Accuracy= 0.92188\n",
      "566\n",
      "Iter 72448, Minibatch Loss= 1403.538574, Training Accuracy= 0.88281\n",
      "567\n",
      "Iter 72576, Minibatch Loss= 499.589874, Training Accuracy= 0.96094\n",
      "568\n",
      "Iter 72704, Minibatch Loss= 339.284363, Training Accuracy= 0.96875\n",
      "569\n",
      "Iter 72832, Minibatch Loss= 528.468872, Training Accuracy= 0.92969\n",
      "570\n",
      "Iter 72960, Minibatch Loss= 1011.094238, Training Accuracy= 0.91406\n",
      "571\n",
      "Iter 73088, Minibatch Loss= 47.518829, Training Accuracy= 0.98438\n",
      "572\n",
      "Iter 73216, Minibatch Loss= 251.695038, Training Accuracy= 0.96094\n",
      "573\n",
      "Iter 73344, Minibatch Loss= 370.466278, Training Accuracy= 0.96875\n",
      "574\n",
      "Iter 73472, Minibatch Loss= 630.801086, Training Accuracy= 0.93750\n",
      "575\n",
      "Iter 73600, Minibatch Loss= 308.590149, Training Accuracy= 0.96875\n",
      "576\n",
      "Iter 73728, Minibatch Loss= 911.768127, Training Accuracy= 0.93750\n",
      "577\n",
      "Iter 73856, Minibatch Loss= 390.217407, Training Accuracy= 0.92969\n",
      "578\n",
      "Iter 73984, Minibatch Loss= 332.597778, Training Accuracy= 0.96094\n",
      "579\n",
      "Iter 74112, Minibatch Loss= 407.788818, Training Accuracy= 0.96094\n",
      "580\n",
      "Iter 74240, Minibatch Loss= 258.626221, Training Accuracy= 0.96875\n",
      "581\n",
      "Iter 74368, Minibatch Loss= 849.942322, Training Accuracy= 0.92969\n",
      "582\n",
      "Iter 74496, Minibatch Loss= 610.250366, Training Accuracy= 0.95312\n",
      "583\n",
      "Iter 74624, Minibatch Loss= 459.311737, Training Accuracy= 0.97656\n",
      "584\n",
      "Iter 74752, Minibatch Loss= 1039.090698, Training Accuracy= 0.92188\n",
      "585\n",
      "Iter 74880, Minibatch Loss= 486.460693, Training Accuracy= 0.94531\n",
      "586\n",
      "Iter 75008, Minibatch Loss= 597.415405, Training Accuracy= 0.96875\n",
      "587\n",
      "Iter 75136, Minibatch Loss= 800.914429, Training Accuracy= 0.92188\n",
      "588\n",
      "Iter 75264, Minibatch Loss= 104.298172, Training Accuracy= 0.97656\n",
      "589\n",
      "Iter 75392, Minibatch Loss= 897.780457, Training Accuracy= 0.93750\n",
      "590\n",
      "Iter 75520, Minibatch Loss= 571.278931, Training Accuracy= 0.94531\n",
      "591\n",
      "Iter 75648, Minibatch Loss= 808.986206, Training Accuracy= 0.95312\n",
      "592\n",
      "Iter 75776, Minibatch Loss= 0.201569, Training Accuracy= 0.99219\n",
      "593\n",
      "Iter 75904, Minibatch Loss= 802.963440, Training Accuracy= 0.93750\n",
      "594\n",
      "Iter 76032, Minibatch Loss= 464.244324, Training Accuracy= 0.93750\n",
      "595\n",
      "Iter 76160, Minibatch Loss= 598.803284, Training Accuracy= 0.96094\n",
      "596\n",
      "Iter 76288, Minibatch Loss= 571.451355, Training Accuracy= 0.96875\n",
      "597\n",
      "Iter 76416, Minibatch Loss= 483.886475, Training Accuracy= 0.94531\n",
      "598\n",
      "Iter 76544, Minibatch Loss= 159.224213, Training Accuracy= 0.96875\n",
      "599\n",
      "Iter 76672, Minibatch Loss= 852.596436, Training Accuracy= 0.93750\n",
      "600\n",
      "Iter 76800, Minibatch Loss= 476.184998, Training Accuracy= 0.97656\n",
      "601\n",
      "Iter 76928, Minibatch Loss= 302.401367, Training Accuracy= 0.96875\n",
      "602\n",
      "Iter 77056, Minibatch Loss= 458.606262, Training Accuracy= 0.96094\n",
      "603\n",
      "Iter 77184, Minibatch Loss= 737.463257, Training Accuracy= 0.93750\n",
      "604\n",
      "Iter 77312, Minibatch Loss= 277.082672, Training Accuracy= 0.96875\n",
      "605\n",
      "Iter 77440, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "606\n",
      "Iter 77568, Minibatch Loss= 454.205627, Training Accuracy= 0.95312\n",
      "607\n",
      "Iter 77696, Minibatch Loss= 425.115845, Training Accuracy= 0.96094\n",
      "608\n",
      "Iter 77824, Minibatch Loss= 276.888123, Training Accuracy= 0.94531\n",
      "609\n",
      "Iter 77952, Minibatch Loss= 325.022217, Training Accuracy= 0.96094\n",
      "610\n",
      "Iter 78080, Minibatch Loss= 546.150330, Training Accuracy= 0.96094\n",
      "611\n",
      "Iter 78208, Minibatch Loss= 259.905914, Training Accuracy= 0.93750\n",
      "612\n",
      "Iter 78336, Minibatch Loss= 523.357666, Training Accuracy= 0.93750\n",
      "613\n",
      "Iter 78464, Minibatch Loss= 489.417480, Training Accuracy= 0.96094\n",
      "614\n",
      "Iter 78592, Minibatch Loss= 897.830811, Training Accuracy= 0.91406\n",
      "615\n",
      "Iter 78720, Minibatch Loss= 715.205627, Training Accuracy= 0.93750\n",
      "616\n",
      "Iter 78848, Minibatch Loss= 254.070007, Training Accuracy= 0.95312\n",
      "617\n",
      "Iter 78976, Minibatch Loss= 209.854828, Training Accuracy= 0.95312\n",
      "618\n",
      "Iter 79104, Minibatch Loss= 131.660980, Training Accuracy= 0.97656\n",
      "619\n",
      "Iter 79232, Minibatch Loss= 236.074615, Training Accuracy= 0.97656\n",
      "620\n",
      "Iter 79360, Minibatch Loss= 718.344604, Training Accuracy= 0.94531\n",
      "621\n",
      "Iter 79488, Minibatch Loss= 279.009277, Training Accuracy= 0.95312\n",
      "622\n",
      "Iter 79616, Minibatch Loss= 365.791992, Training Accuracy= 0.96875\n",
      "623\n",
      "Iter 79744, Minibatch Loss= 636.126160, Training Accuracy= 0.93750\n",
      "624\n",
      "Iter 79872, Minibatch Loss= 403.309692, Training Accuracy= 0.96094\n",
      "625\n",
      "Iter 80000, Minibatch Loss= 905.998962, Training Accuracy= 0.93750\n",
      "626\n",
      "Iter 80128, Minibatch Loss= 386.918274, Training Accuracy= 0.94531\n",
      "627\n",
      "Iter 80256, Minibatch Loss= 214.094452, Training Accuracy= 0.96875\n",
      "628\n",
      "Iter 80384, Minibatch Loss= 502.862732, Training Accuracy= 0.93750\n",
      "629\n",
      "Iter 80512, Minibatch Loss= 167.725510, Training Accuracy= 0.96094\n",
      "630\n",
      "Iter 80640, Minibatch Loss= 342.105194, Training Accuracy= 0.97656\n",
      "631\n",
      "Iter 80768, Minibatch Loss= 853.065796, Training Accuracy= 0.91406\n",
      "632\n",
      "Iter 80896, Minibatch Loss= 151.254410, Training Accuracy= 0.96094\n",
      "633\n",
      "Iter 81024, Minibatch Loss= 858.005859, Training Accuracy= 0.91406\n",
      "634\n",
      "Iter 81152, Minibatch Loss= 703.296631, Training Accuracy= 0.95312\n",
      "635\n",
      "Iter 81280, Minibatch Loss= 742.628113, Training Accuracy= 0.92188\n",
      "636\n",
      "Iter 81408, Minibatch Loss= 398.731567, Training Accuracy= 0.96875\n",
      "637\n",
      "Iter 81536, Minibatch Loss= 1048.987793, Training Accuracy= 0.92969\n",
      "638\n",
      "Iter 81664, Minibatch Loss= 525.726013, Training Accuracy= 0.93750\n",
      "639\n",
      "Iter 81792, Minibatch Loss= 578.835571, Training Accuracy= 0.95312\n",
      "640\n",
      "Iter 81920, Minibatch Loss= 651.799683, Training Accuracy= 0.91406\n",
      "641\n",
      "Iter 82048, Minibatch Loss= 445.147308, Training Accuracy= 0.92188\n",
      "642\n",
      "Iter 82176, Minibatch Loss= 856.518066, Training Accuracy= 0.94531\n",
      "643\n",
      "Iter 82304, Minibatch Loss= 384.516663, Training Accuracy= 0.93750\n",
      "644\n",
      "Iter 82432, Minibatch Loss= 112.467392, Training Accuracy= 0.96875\n",
      "645\n",
      "Iter 82560, Minibatch Loss= 188.260590, Training Accuracy= 0.97656\n",
      "646\n",
      "Iter 82688, Minibatch Loss= 344.000366, Training Accuracy= 0.92969\n",
      "647\n",
      "Iter 82816, Minibatch Loss= 510.288452, Training Accuracy= 0.96094\n",
      "648\n",
      "Iter 82944, Minibatch Loss= 60.619202, Training Accuracy= 0.98438\n",
      "649\n",
      "Iter 83072, Minibatch Loss= 113.571686, Training Accuracy= 0.96094\n",
      "650\n",
      "Iter 83200, Minibatch Loss= 747.123962, Training Accuracy= 0.94531\n",
      "651\n",
      "Iter 83328, Minibatch Loss= 82.663452, Training Accuracy= 0.99219\n",
      "652\n",
      "Iter 83456, Minibatch Loss= 330.764160, Training Accuracy= 0.96875\n",
      "653\n",
      "Iter 83584, Minibatch Loss= 101.547104, Training Accuracy= 0.98438\n",
      "654\n",
      "Iter 83712, Minibatch Loss= 387.767029, Training Accuracy= 0.94531\n",
      "655\n",
      "Iter 83840, Minibatch Loss= 127.444435, Training Accuracy= 0.96094\n",
      "656\n",
      "Iter 83968, Minibatch Loss= 498.115540, Training Accuracy= 0.96094\n",
      "657\n",
      "Iter 84096, Minibatch Loss= 849.231628, Training Accuracy= 0.92969\n",
      "658\n",
      "Iter 84224, Minibatch Loss= 259.090149, Training Accuracy= 0.97656\n",
      "659\n",
      "Iter 84352, Minibatch Loss= 327.410767, Training Accuracy= 0.96094\n",
      "660\n",
      "Iter 84480, Minibatch Loss= 395.733459, Training Accuracy= 0.95312\n",
      "661\n",
      "Iter 84608, Minibatch Loss= 738.634277, Training Accuracy= 0.95312\n",
      "662\n",
      "Iter 84736, Minibatch Loss= 493.089111, Training Accuracy= 0.94531\n",
      "663\n",
      "Iter 84864, Minibatch Loss= 267.810059, Training Accuracy= 0.96875\n",
      "664\n",
      "Iter 84992, Minibatch Loss= 104.655075, Training Accuracy= 0.96875\n",
      "665\n",
      "Iter 85120, Minibatch Loss= 452.116394, Training Accuracy= 0.94531\n",
      "666\n",
      "Iter 85248, Minibatch Loss= 305.093323, Training Accuracy= 0.96094\n",
      "667\n",
      "Iter 85376, Minibatch Loss= 281.604126, Training Accuracy= 0.94531\n",
      "668\n",
      "Iter 85504, Minibatch Loss= 462.927856, Training Accuracy= 0.94531\n",
      "669\n",
      "Iter 85632, Minibatch Loss= 360.912567, Training Accuracy= 0.96875\n",
      "670\n",
      "Iter 85760, Minibatch Loss= 448.639099, Training Accuracy= 0.94531\n",
      "671\n",
      "Iter 85888, Minibatch Loss= 243.579605, Training Accuracy= 0.96094\n",
      "672\n",
      "Iter 86016, Minibatch Loss= 690.219543, Training Accuracy= 0.94531\n",
      "673\n",
      "Iter 86144, Minibatch Loss= 313.232910, Training Accuracy= 0.96094\n",
      "674\n",
      "Iter 86272, Minibatch Loss= 113.786102, Training Accuracy= 0.98438\n",
      "675\n",
      "Iter 86400, Minibatch Loss= 597.263428, Training Accuracy= 0.93750\n",
      "676\n",
      "Iter 86528, Minibatch Loss= 248.996750, Training Accuracy= 0.96875\n",
      "677\n",
      "Iter 86656, Minibatch Loss= 64.272873, Training Accuracy= 0.98438\n",
      "678\n",
      "Iter 86784, Minibatch Loss= 567.810791, Training Accuracy= 0.96875\n",
      "679\n",
      "Iter 86912, Minibatch Loss= 91.979469, Training Accuracy= 0.96875\n",
      "680\n",
      "Iter 87040, Minibatch Loss= 658.482056, Training Accuracy= 0.94531\n",
      "681\n",
      "Iter 87168, Minibatch Loss= 346.060303, Training Accuracy= 0.97656\n",
      "682\n",
      "Iter 87296, Minibatch Loss= 950.861877, Training Accuracy= 0.93750\n",
      "683\n",
      "Iter 87424, Minibatch Loss= 171.840286, Training Accuracy= 0.97656\n",
      "684\n",
      "Iter 87552, Minibatch Loss= 402.403046, Training Accuracy= 0.93750\n",
      "685\n",
      "Iter 87680, Minibatch Loss= 187.873825, Training Accuracy= 0.96094\n",
      "686\n",
      "Iter 87808, Minibatch Loss= 749.946655, Training Accuracy= 0.92188\n",
      "687\n",
      "Iter 87936, Minibatch Loss= 308.041016, Training Accuracy= 0.94531\n",
      "688\n",
      "Iter 88064, Minibatch Loss= 227.446487, Training Accuracy= 0.96875\n",
      "689\n",
      "Iter 88192, Minibatch Loss= 563.003479, Training Accuracy= 0.95312\n",
      "690\n",
      "Iter 88320, Minibatch Loss= 287.624908, Training Accuracy= 0.95312\n",
      "691\n",
      "Iter 88448, Minibatch Loss= 202.714111, Training Accuracy= 0.96875\n",
      "692\n",
      "Iter 88576, Minibatch Loss= 457.007538, Training Accuracy= 0.94531\n",
      "693\n",
      "Iter 88704, Minibatch Loss= 403.352051, Training Accuracy= 0.96094\n",
      "694\n",
      "Iter 88832, Minibatch Loss= 265.379639, Training Accuracy= 0.98438\n",
      "695\n",
      "Iter 88960, Minibatch Loss= 375.687012, Training Accuracy= 0.94531\n",
      "696\n",
      "Iter 89088, Minibatch Loss= 328.763000, Training Accuracy= 0.97656\n",
      "697\n",
      "Iter 89216, Minibatch Loss= 282.706787, Training Accuracy= 0.96094\n",
      "698\n",
      "Iter 89344, Minibatch Loss= 259.726196, Training Accuracy= 0.96094\n",
      "699\n",
      "Iter 89472, Minibatch Loss= 153.102417, Training Accuracy= 0.96875\n",
      "700\n",
      "Iter 89600, Minibatch Loss= 368.765717, Training Accuracy= 0.93750\n",
      "701\n",
      "Iter 89728, Minibatch Loss= 377.927551, Training Accuracy= 0.95312\n",
      "702\n",
      "Iter 89856, Minibatch Loss= 650.743713, Training Accuracy= 0.94531\n",
      "703\n",
      "Iter 89984, Minibatch Loss= 637.583984, Training Accuracy= 0.94531\n",
      "704\n",
      "Iter 90112, Minibatch Loss= 602.782715, Training Accuracy= 0.94531\n",
      "705\n",
      "Iter 90240, Minibatch Loss= 848.131165, Training Accuracy= 0.94531\n",
      "706\n",
      "Iter 90368, Minibatch Loss= 589.033447, Training Accuracy= 0.95312\n",
      "707\n",
      "Iter 90496, Minibatch Loss= 263.060730, Training Accuracy= 0.96094\n",
      "708\n",
      "Iter 90624, Minibatch Loss= 524.291260, Training Accuracy= 0.95312\n",
      "709\n",
      "Iter 90752, Minibatch Loss= 366.450958, Training Accuracy= 0.94531\n",
      "710\n",
      "Iter 90880, Minibatch Loss= 350.226624, Training Accuracy= 0.95312\n",
      "711\n",
      "Iter 91008, Minibatch Loss= 441.093689, Training Accuracy= 0.95312\n",
      "712\n",
      "Iter 91136, Minibatch Loss= 362.063019, Training Accuracy= 0.94531\n",
      "713\n",
      "Iter 91264, Minibatch Loss= 765.634888, Training Accuracy= 0.94531\n",
      "714\n",
      "Iter 91392, Minibatch Loss= 285.966766, Training Accuracy= 0.94531\n",
      "715\n",
      "Iter 91520, Minibatch Loss= 669.836304, Training Accuracy= 0.94531\n",
      "716\n",
      "Iter 91648, Minibatch Loss= 165.755722, Training Accuracy= 0.97656\n",
      "717\n",
      "Iter 91776, Minibatch Loss= 348.941315, Training Accuracy= 0.94531\n",
      "718\n",
      "Iter 91904, Minibatch Loss= 332.653564, Training Accuracy= 0.94531\n",
      "719\n",
      "Iter 92032, Minibatch Loss= 372.452942, Training Accuracy= 0.96094\n",
      "720\n",
      "Iter 92160, Minibatch Loss= 313.333130, Training Accuracy= 0.95312\n",
      "721\n",
      "Iter 92288, Minibatch Loss= 202.547028, Training Accuracy= 0.95312\n",
      "722\n",
      "Iter 92416, Minibatch Loss= 365.175232, Training Accuracy= 0.96094\n",
      "723\n",
      "Iter 92544, Minibatch Loss= 402.063507, Training Accuracy= 0.96094\n",
      "724\n",
      "Iter 92672, Minibatch Loss= 516.477417, Training Accuracy= 0.93750\n",
      "725\n",
      "Iter 92800, Minibatch Loss= 112.386017, Training Accuracy= 0.97656\n",
      "726\n",
      "Iter 92928, Minibatch Loss= 92.153198, Training Accuracy= 0.96875\n",
      "727\n",
      "Iter 93056, Minibatch Loss= 89.419647, Training Accuracy= 0.97656\n",
      "728\n",
      "Iter 93184, Minibatch Loss= 217.752838, Training Accuracy= 0.96094\n",
      "729\n",
      "Iter 93312, Minibatch Loss= 466.853302, Training Accuracy= 0.95312\n",
      "730\n",
      "Iter 93440, Minibatch Loss= 717.178589, Training Accuracy= 0.95312\n",
      "731\n",
      "Iter 93568, Minibatch Loss= 785.903076, Training Accuracy= 0.96875\n",
      "732\n",
      "Iter 93696, Minibatch Loss= 285.879333, Training Accuracy= 0.96875\n",
      "733\n",
      "Iter 93824, Minibatch Loss= 505.967896, Training Accuracy= 0.94531\n",
      "734\n",
      "Iter 93952, Minibatch Loss= 311.487915, Training Accuracy= 0.95312\n",
      "735\n",
      "Iter 94080, Minibatch Loss= 1092.966309, Training Accuracy= 0.89062\n",
      "736\n",
      "Iter 94208, Minibatch Loss= 536.289001, Training Accuracy= 0.92969\n",
      "737\n",
      "Iter 94336, Minibatch Loss= 76.118744, Training Accuracy= 0.99219\n",
      "738\n",
      "Iter 94464, Minibatch Loss= 1158.729248, Training Accuracy= 0.94531\n",
      "739\n",
      "Iter 94592, Minibatch Loss= 292.232788, Training Accuracy= 0.96094\n",
      "740\n",
      "Iter 94720, Minibatch Loss= 310.318573, Training Accuracy= 0.96875\n",
      "741\n",
      "Iter 94848, Minibatch Loss= 865.932617, Training Accuracy= 0.92188\n",
      "742\n",
      "Iter 94976, Minibatch Loss= 179.436127, Training Accuracy= 0.98438\n",
      "743\n",
      "Iter 95104, Minibatch Loss= 161.505356, Training Accuracy= 0.96875\n",
      "744\n",
      "Iter 95232, Minibatch Loss= 544.530640, Training Accuracy= 0.96094\n",
      "745\n",
      "Iter 95360, Minibatch Loss= 613.778198, Training Accuracy= 0.91406\n",
      "746\n",
      "Iter 95488, Minibatch Loss= 608.230957, Training Accuracy= 0.94531\n",
      "747\n",
      "Iter 95616, Minibatch Loss= 896.321411, Training Accuracy= 0.94531\n",
      "748\n",
      "Iter 95744, Minibatch Loss= 519.764099, Training Accuracy= 0.95312\n",
      "749\n",
      "Iter 95872, Minibatch Loss= 168.836945, Training Accuracy= 0.96875\n",
      "750\n",
      "Iter 96000, Minibatch Loss= 364.702820, Training Accuracy= 0.94531\n",
      "751\n",
      "Iter 96128, Minibatch Loss= 1010.509277, Training Accuracy= 0.93750\n",
      "752\n",
      "Iter 96256, Minibatch Loss= 251.083405, Training Accuracy= 0.95312\n",
      "753\n",
      "Iter 96384, Minibatch Loss= 120.821747, Training Accuracy= 0.94531\n",
      "754\n",
      "Iter 96512, Minibatch Loss= 379.468536, Training Accuracy= 0.95312\n",
      "755\n",
      "Iter 96640, Minibatch Loss= 220.217255, Training Accuracy= 0.97656\n",
      "756\n",
      "Iter 96768, Minibatch Loss= 331.077942, Training Accuracy= 0.96875\n",
      "757\n",
      "Iter 96896, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "758\n",
      "Iter 97024, Minibatch Loss= 285.128845, Training Accuracy= 0.96875\n",
      "759\n",
      "Iter 97152, Minibatch Loss= 876.699585, Training Accuracy= 0.96875\n",
      "760\n",
      "Iter 97280, Minibatch Loss= 483.623169, Training Accuracy= 0.94531\n",
      "761\n",
      "Iter 97408, Minibatch Loss= 342.487915, Training Accuracy= 0.95312\n",
      "762\n",
      "Iter 97536, Minibatch Loss= 370.010437, Training Accuracy= 0.94531\n",
      "763\n",
      "Iter 97664, Minibatch Loss= 209.312332, Training Accuracy= 0.98438\n",
      "764\n",
      "Iter 97792, Minibatch Loss= 369.938599, Training Accuracy= 0.93750\n",
      "765\n",
      "Iter 97920, Minibatch Loss= 786.656006, Training Accuracy= 0.92188\n",
      "766\n",
      "Iter 98048, Minibatch Loss= 66.586777, Training Accuracy= 0.98438\n",
      "767\n",
      "Iter 98176, Minibatch Loss= 586.651489, Training Accuracy= 0.92188\n",
      "768\n",
      "Iter 98304, Minibatch Loss= 238.147003, Training Accuracy= 0.96875\n",
      "769\n",
      "Iter 98432, Minibatch Loss= 288.075378, Training Accuracy= 0.95312\n",
      "770\n",
      "Iter 98560, Minibatch Loss= 423.602509, Training Accuracy= 0.96875\n",
      "771\n",
      "Iter 98688, Minibatch Loss= 218.651428, Training Accuracy= 0.98438\n",
      "772\n",
      "Iter 98816, Minibatch Loss= 307.631104, Training Accuracy= 0.92969\n",
      "773\n",
      "Iter 98944, Minibatch Loss= 242.205048, Training Accuracy= 0.96094\n",
      "774\n",
      "Iter 99072, Minibatch Loss= 339.690308, Training Accuracy= 0.96875\n",
      "775\n",
      "Iter 99200, Minibatch Loss= 367.559387, Training Accuracy= 0.96875\n",
      "776\n",
      "Iter 99328, Minibatch Loss= 123.641403, Training Accuracy= 0.97656\n",
      "777\n",
      "Iter 99456, Minibatch Loss= 531.437988, Training Accuracy= 0.93750\n",
      "778\n",
      "Iter 99584, Minibatch Loss= 149.584641, Training Accuracy= 0.97656\n",
      "779\n",
      "Iter 99712, Minibatch Loss= 216.170105, Training Accuracy= 0.96875\n",
      "780\n",
      "Iter 99840, Minibatch Loss= 50.499908, Training Accuracy= 0.98438\n",
      "781\n",
      "Iter 99968, Minibatch Loss= 345.846619, Training Accuracy= 0.93750\n",
      "782\n",
      "Iter 100096, Minibatch Loss= 265.747559, Training Accuracy= 0.99219\n",
      "783\n",
      "Iter 100224, Minibatch Loss= 1015.947083, Training Accuracy= 0.94531\n",
      "784\n",
      "Iter 100352, Minibatch Loss= 218.909180, Training Accuracy= 0.98438\n",
      "785\n",
      "Iter 100480, Minibatch Loss= 658.581909, Training Accuracy= 0.91406\n",
      "786\n",
      "Iter 100608, Minibatch Loss= 506.265991, Training Accuracy= 0.92969\n",
      "787\n",
      "Iter 100736, Minibatch Loss= 809.805603, Training Accuracy= 0.92969\n",
      "788\n",
      "Iter 100864, Minibatch Loss= 100.991333, Training Accuracy= 0.98438\n",
      "789\n",
      "Iter 100992, Minibatch Loss= 249.140182, Training Accuracy= 0.96875\n",
      "790\n",
      "Iter 101120, Minibatch Loss= 493.362732, Training Accuracy= 0.94531\n",
      "791\n",
      "Iter 101248, Minibatch Loss= 45.589699, Training Accuracy= 0.97656\n",
      "792\n",
      "Iter 101376, Minibatch Loss= 356.008423, Training Accuracy= 0.96875\n",
      "793\n",
      "Iter 101504, Minibatch Loss= 394.312927, Training Accuracy= 0.96875\n",
      "794\n",
      "Iter 101632, Minibatch Loss= 743.679504, Training Accuracy= 0.93750\n",
      "795\n",
      "Iter 101760, Minibatch Loss= 276.078125, Training Accuracy= 0.96875\n",
      "796\n",
      "Iter 101888, Minibatch Loss= 162.134155, Training Accuracy= 0.96875\n",
      "797\n",
      "Iter 102016, Minibatch Loss= 273.315308, Training Accuracy= 0.96875\n",
      "798\n",
      "Iter 102144, Minibatch Loss= 196.471802, Training Accuracy= 0.96094\n",
      "799\n",
      "Iter 102272, Minibatch Loss= 633.872437, Training Accuracy= 0.93750\n",
      "800\n",
      "Iter 102400, Minibatch Loss= 839.288574, Training Accuracy= 0.92188\n",
      "801\n",
      "Iter 102528, Minibatch Loss= 309.131592, Training Accuracy= 0.96094\n",
      "802\n",
      "Iter 102656, Minibatch Loss= 127.624344, Training Accuracy= 0.97656\n",
      "803\n",
      "Iter 102784, Minibatch Loss= 163.708115, Training Accuracy= 0.96875\n",
      "804\n",
      "Iter 102912, Minibatch Loss= 164.409821, Training Accuracy= 0.96094\n",
      "805\n",
      "Iter 103040, Minibatch Loss= 533.799316, Training Accuracy= 0.94531\n",
      "806\n",
      "Iter 103168, Minibatch Loss= 315.607941, Training Accuracy= 0.96875\n",
      "807\n",
      "Iter 103296, Minibatch Loss= 614.176453, Training Accuracy= 0.92969\n",
      "808\n",
      "Iter 103424, Minibatch Loss= 261.409607, Training Accuracy= 0.96875\n",
      "809\n",
      "Iter 103552, Minibatch Loss= 577.447510, Training Accuracy= 0.92969\n",
      "810\n",
      "Iter 103680, Minibatch Loss= 128.627869, Training Accuracy= 0.96875\n",
      "811\n",
      "Iter 103808, Minibatch Loss= 635.955811, Training Accuracy= 0.94531\n",
      "812\n",
      "Iter 103936, Minibatch Loss= 283.452423, Training Accuracy= 0.96094\n",
      "813\n",
      "Iter 104064, Minibatch Loss= 339.630219, Training Accuracy= 0.97656\n",
      "814\n",
      "Iter 104192, Minibatch Loss= 221.964325, Training Accuracy= 0.97656\n",
      "815\n",
      "Iter 104320, Minibatch Loss= 287.532654, Training Accuracy= 0.94531\n",
      "816\n",
      "Iter 104448, Minibatch Loss= 378.966919, Training Accuracy= 0.93750\n",
      "817\n",
      "Iter 104576, Minibatch Loss= 351.514496, Training Accuracy= 0.96094\n",
      "818\n",
      "Iter 104704, Minibatch Loss= 608.752319, Training Accuracy= 0.95312\n",
      "819\n",
      "Iter 104832, Minibatch Loss= 433.015320, Training Accuracy= 0.96875\n",
      "820\n",
      "Iter 104960, Minibatch Loss= 49.403183, Training Accuracy= 0.99219\n",
      "821\n",
      "Iter 105088, Minibatch Loss= 691.520874, Training Accuracy= 0.92188\n",
      "822\n",
      "Iter 105216, Minibatch Loss= 684.012512, Training Accuracy= 0.93750\n",
      "823\n",
      "Iter 105344, Minibatch Loss= 119.286926, Training Accuracy= 0.97656\n",
      "824\n",
      "Iter 105472, Minibatch Loss= 40.518166, Training Accuracy= 0.97656\n",
      "825\n",
      "Iter 105600, Minibatch Loss= 163.817413, Training Accuracy= 0.97656\n",
      "826\n",
      "Iter 105728, Minibatch Loss= 70.579552, Training Accuracy= 0.97656\n",
      "827\n",
      "Iter 105856, Minibatch Loss= 204.651459, Training Accuracy= 0.96875\n",
      "828\n",
      "Iter 105984, Minibatch Loss= 231.577286, Training Accuracy= 0.94531\n",
      "829\n",
      "Iter 106112, Minibatch Loss= 295.179993, Training Accuracy= 0.94531\n",
      "830\n",
      "Iter 106240, Minibatch Loss= 89.542366, Training Accuracy= 0.96094\n",
      "831\n",
      "Iter 106368, Minibatch Loss= 246.632706, Training Accuracy= 0.95312\n",
      "832\n",
      "Iter 106496, Minibatch Loss= 762.497498, Training Accuracy= 0.95312\n",
      "833\n",
      "Iter 106624, Minibatch Loss= 510.009094, Training Accuracy= 0.96094\n",
      "834\n",
      "Iter 106752, Minibatch Loss= 60.324722, Training Accuracy= 0.97656\n",
      "835\n",
      "Iter 106880, Minibatch Loss= 394.645813, Training Accuracy= 0.95312\n",
      "836\n",
      "Iter 107008, Minibatch Loss= 444.121216, Training Accuracy= 0.92969\n",
      "837\n",
      "Iter 107136, Minibatch Loss= 281.233215, Training Accuracy= 0.96094\n",
      "838\n",
      "Iter 107264, Minibatch Loss= 37.471321, Training Accuracy= 0.99219\n",
      "839\n",
      "Iter 107392, Minibatch Loss= 150.093719, Training Accuracy= 0.97656\n",
      "840\n",
      "Iter 107520, Minibatch Loss= 233.605148, Training Accuracy= 0.96875\n",
      "841\n",
      "Iter 107648, Minibatch Loss= 673.741943, Training Accuracy= 0.94531\n",
      "842\n",
      "Iter 107776, Minibatch Loss= 342.603607, Training Accuracy= 0.96094\n",
      "843\n",
      "Iter 107904, Minibatch Loss= 525.455383, Training Accuracy= 0.95312\n",
      "844\n",
      "Iter 108032, Minibatch Loss= 537.257935, Training Accuracy= 0.95312\n",
      "845\n",
      "Iter 108160, Minibatch Loss= 175.717499, Training Accuracy= 0.96875\n",
      "846\n",
      "Iter 108288, Minibatch Loss= 255.877579, Training Accuracy= 0.95312\n",
      "847\n",
      "Iter 108416, Minibatch Loss= 984.037354, Training Accuracy= 0.89844\n",
      "848\n",
      "Iter 108544, Minibatch Loss= 222.526108, Training Accuracy= 0.96094\n",
      "849\n",
      "Iter 108672, Minibatch Loss= 281.354919, Training Accuracy= 0.95312\n",
      "850\n",
      "Iter 108800, Minibatch Loss= 406.988159, Training Accuracy= 0.93750\n",
      "851\n",
      "Iter 108928, Minibatch Loss= 292.332214, Training Accuracy= 0.96875\n",
      "852\n",
      "Iter 109056, Minibatch Loss= 112.985359, Training Accuracy= 0.97656\n",
      "853\n",
      "Iter 109184, Minibatch Loss= 148.554382, Training Accuracy= 0.96875\n",
      "854\n",
      "Iter 109312, Minibatch Loss= 543.620789, Training Accuracy= 0.95312\n",
      "855\n",
      "Iter 109440, Minibatch Loss= 813.717773, Training Accuracy= 0.96094\n",
      "856\n",
      "Iter 109568, Minibatch Loss= 204.914642, Training Accuracy= 0.97656\n",
      "857\n",
      "Iter 109696, Minibatch Loss= 391.539673, Training Accuracy= 0.96094\n",
      "858\n",
      "Iter 109824, Minibatch Loss= 110.162262, Training Accuracy= 0.97656\n",
      "859\n",
      "Iter 109952, Minibatch Loss= 196.326889, Training Accuracy= 0.96875\n",
      "860\n",
      "Iter 110080, Minibatch Loss= 409.847839, Training Accuracy= 0.96094\n",
      "861\n",
      "Iter 110208, Minibatch Loss= 406.028625, Training Accuracy= 0.94531\n",
      "862\n",
      "Iter 110336, Minibatch Loss= 399.301392, Training Accuracy= 0.94531\n",
      "863\n",
      "Iter 110464, Minibatch Loss= 177.932281, Training Accuracy= 0.95312\n",
      "864\n",
      "Iter 110592, Minibatch Loss= 379.744995, Training Accuracy= 0.92188\n",
      "865\n",
      "Iter 110720, Minibatch Loss= 126.765327, Training Accuracy= 0.96875\n",
      "866\n",
      "Iter 110848, Minibatch Loss= 260.626343, Training Accuracy= 0.95312\n",
      "867\n",
      "Iter 110976, Minibatch Loss= 102.297409, Training Accuracy= 0.98438\n",
      "868\n",
      "Iter 111104, Minibatch Loss= 232.413254, Training Accuracy= 0.96875\n",
      "869\n",
      "Iter 111232, Minibatch Loss= 388.524841, Training Accuracy= 0.94531\n",
      "870\n",
      "Iter 111360, Minibatch Loss= 142.908173, Training Accuracy= 0.96094\n",
      "871\n",
      "Iter 111488, Minibatch Loss= 391.982727, Training Accuracy= 0.96094\n",
      "872\n",
      "Iter 111616, Minibatch Loss= 246.620941, Training Accuracy= 0.96875\n",
      "873\n",
      "Iter 111744, Minibatch Loss= 328.653809, Training Accuracy= 0.95312\n",
      "874\n",
      "Iter 111872, Minibatch Loss= 283.208191, Training Accuracy= 0.96094\n",
      "875\n",
      "Iter 112000, Minibatch Loss= 191.059769, Training Accuracy= 0.96094\n",
      "876\n",
      "Iter 112128, Minibatch Loss= 597.987122, Training Accuracy= 0.93750\n",
      "877\n",
      "Iter 112256, Minibatch Loss= 328.351868, Training Accuracy= 0.96875\n",
      "878\n",
      "Iter 112384, Minibatch Loss= 2.432831, Training Accuracy= 0.99219\n",
      "879\n",
      "Iter 112512, Minibatch Loss= 77.016228, Training Accuracy= 0.98438\n",
      "880\n",
      "Iter 112640, Minibatch Loss= 94.818367, Training Accuracy= 0.97656\n",
      "881\n",
      "Iter 112768, Minibatch Loss= 323.046204, Training Accuracy= 0.96094\n",
      "882\n",
      "Iter 112896, Minibatch Loss= 192.681763, Training Accuracy= 0.98438\n",
      "883\n",
      "Iter 113024, Minibatch Loss= 39.243111, Training Accuracy= 0.97656\n",
      "884\n",
      "Iter 113152, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "885\n",
      "Iter 113280, Minibatch Loss= 250.469009, Training Accuracy= 0.96094\n",
      "886\n",
      "Iter 113408, Minibatch Loss= 74.330734, Training Accuracy= 0.96875\n",
      "887\n",
      "Iter 113536, Minibatch Loss= 190.564026, Training Accuracy= 0.97656\n",
      "888\n",
      "Iter 113664, Minibatch Loss= 285.409668, Training Accuracy= 0.97656\n",
      "889\n",
      "Iter 113792, Minibatch Loss= 196.577759, Training Accuracy= 0.94531\n",
      "890\n",
      "Iter 113920, Minibatch Loss= 210.866760, Training Accuracy= 0.97656\n",
      "891\n",
      "Iter 114048, Minibatch Loss= 187.558609, Training Accuracy= 0.96094\n",
      "892\n",
      "Iter 114176, Minibatch Loss= 232.168167, Training Accuracy= 0.95312\n",
      "893\n",
      "Iter 114304, Minibatch Loss= 335.026855, Training Accuracy= 0.95312\n",
      "894\n",
      "Iter 114432, Minibatch Loss= 5.600021, Training Accuracy= 0.98438\n",
      "895\n",
      "Iter 114560, Minibatch Loss= 164.618942, Training Accuracy= 0.96094\n",
      "896\n",
      "Iter 114688, Minibatch Loss= 203.214355, Training Accuracy= 0.95312\n",
      "897\n",
      "Iter 114816, Minibatch Loss= 177.106598, Training Accuracy= 0.96875\n",
      "898\n",
      "Iter 114944, Minibatch Loss= 292.061523, Training Accuracy= 0.96875\n",
      "899\n",
      "Iter 115072, Minibatch Loss= 272.116119, Training Accuracy= 0.96094\n",
      "900\n",
      "Iter 115200, Minibatch Loss= 534.718323, Training Accuracy= 0.93750\n",
      "901\n",
      "Iter 115328, Minibatch Loss= 646.092468, Training Accuracy= 0.92969\n",
      "902\n",
      "Iter 115456, Minibatch Loss= 666.536133, Training Accuracy= 0.92969\n",
      "903\n",
      "Iter 115584, Minibatch Loss= 129.581390, Training Accuracy= 0.98438\n",
      "904\n",
      "Iter 115712, Minibatch Loss= 223.946930, Training Accuracy= 0.96875\n",
      "905\n",
      "Iter 115840, Minibatch Loss= 82.986374, Training Accuracy= 0.96875\n",
      "906\n",
      "Iter 115968, Minibatch Loss= 593.603149, Training Accuracy= 0.94531\n",
      "907\n",
      "Iter 116096, Minibatch Loss= 330.306641, Training Accuracy= 0.96875\n",
      "908\n",
      "Iter 116224, Minibatch Loss= 100.840401, Training Accuracy= 0.97656\n",
      "909\n",
      "Iter 116352, Minibatch Loss= 245.523148, Training Accuracy= 0.96875\n",
      "910\n",
      "Iter 116480, Minibatch Loss= 85.597061, Training Accuracy= 0.97656\n",
      "911\n",
      "Iter 116608, Minibatch Loss= 79.368896, Training Accuracy= 0.97656\n",
      "912\n",
      "Iter 116736, Minibatch Loss= 274.173889, Training Accuracy= 0.96875\n",
      "913\n",
      "Iter 116864, Minibatch Loss= 281.287506, Training Accuracy= 0.97656\n",
      "914\n",
      "Iter 116992, Minibatch Loss= 357.227112, Training Accuracy= 0.95312\n",
      "915\n",
      "Iter 117120, Minibatch Loss= 256.930664, Training Accuracy= 0.94531\n",
      "916\n",
      "Iter 117248, Minibatch Loss= 58.739128, Training Accuracy= 0.96875\n",
      "917\n",
      "Iter 117376, Minibatch Loss= 623.837341, Training Accuracy= 0.92188\n",
      "918\n",
      "Iter 117504, Minibatch Loss= 217.271957, Training Accuracy= 0.96094\n",
      "919\n",
      "Iter 117632, Minibatch Loss= 504.186310, Training Accuracy= 0.94531\n",
      "920\n",
      "Iter 117760, Minibatch Loss= 505.099884, Training Accuracy= 0.92969\n",
      "921\n",
      "Iter 117888, Minibatch Loss= 412.890198, Training Accuracy= 0.92969\n",
      "922\n",
      "Iter 118016, Minibatch Loss= 146.252457, Training Accuracy= 0.97656\n",
      "923\n",
      "Iter 118144, Minibatch Loss= 325.344360, Training Accuracy= 0.96094\n",
      "924\n",
      "Iter 118272, Minibatch Loss= 159.055710, Training Accuracy= 0.97656\n",
      "925\n",
      "Iter 118400, Minibatch Loss= 306.785858, Training Accuracy= 0.96094\n",
      "926\n",
      "Iter 118528, Minibatch Loss= 68.589401, Training Accuracy= 0.97656\n",
      "927\n",
      "Iter 118656, Minibatch Loss= 195.239853, Training Accuracy= 0.97656\n",
      "928\n",
      "Iter 118784, Minibatch Loss= 254.837418, Training Accuracy= 0.96875\n",
      "929\n",
      "Iter 118912, Minibatch Loss= 598.224243, Training Accuracy= 0.94531\n",
      "930\n",
      "Iter 119040, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "931\n",
      "Iter 119168, Minibatch Loss= 302.353058, Training Accuracy= 0.96875\n",
      "932\n",
      "Iter 119296, Minibatch Loss= 151.017075, Training Accuracy= 0.97656\n",
      "933\n",
      "Iter 119424, Minibatch Loss= 231.805786, Training Accuracy= 0.96875\n",
      "934\n",
      "Iter 119552, Minibatch Loss= 75.661346, Training Accuracy= 0.98438\n",
      "935\n",
      "Iter 119680, Minibatch Loss= 179.876450, Training Accuracy= 0.97656\n",
      "936\n",
      "Iter 119808, Minibatch Loss= 163.341812, Training Accuracy= 0.95312\n",
      "937\n",
      "Iter 119936, Minibatch Loss= 215.982315, Training Accuracy= 0.96094\n",
      "938\n",
      "Iter 120064, Minibatch Loss= 311.459137, Training Accuracy= 0.96094\n",
      "939\n",
      "Iter 120192, Minibatch Loss= 152.044388, Training Accuracy= 0.96094\n",
      "940\n",
      "Iter 120320, Minibatch Loss= 535.307678, Training Accuracy= 0.92969\n",
      "941\n",
      "Iter 120448, Minibatch Loss= 319.989777, Training Accuracy= 0.94531\n",
      "942\n",
      "Iter 120576, Minibatch Loss= 121.905914, Training Accuracy= 0.96094\n",
      "943\n",
      "Iter 120704, Minibatch Loss= 255.117859, Training Accuracy= 0.96875\n",
      "944\n",
      "Iter 120832, Minibatch Loss= 267.606140, Training Accuracy= 0.97656\n",
      "945\n",
      "Iter 120960, Minibatch Loss= 29.829407, Training Accuracy= 0.98438\n",
      "946\n",
      "Iter 121088, Minibatch Loss= 10.321716, Training Accuracy= 0.98438\n",
      "947\n",
      "Iter 121216, Minibatch Loss= 189.011124, Training Accuracy= 0.96875\n",
      "948\n",
      "Iter 121344, Minibatch Loss= 341.759094, Training Accuracy= 0.96094\n",
      "949\n",
      "Iter 121472, Minibatch Loss= 365.000183, Training Accuracy= 0.95312\n",
      "950\n",
      "Iter 121600, Minibatch Loss= 424.937256, Training Accuracy= 0.96094\n",
      "951\n",
      "Iter 121728, Minibatch Loss= 606.051392, Training Accuracy= 0.95312\n",
      "952\n",
      "Iter 121856, Minibatch Loss= 156.865891, Training Accuracy= 0.98438\n",
      "953\n",
      "Iter 121984, Minibatch Loss= 445.183197, Training Accuracy= 0.94531\n",
      "954\n",
      "Iter 122112, Minibatch Loss= 150.756042, Training Accuracy= 0.97656\n",
      "955\n",
      "Iter 122240, Minibatch Loss= 149.206711, Training Accuracy= 0.96875\n",
      "956\n",
      "Iter 122368, Minibatch Loss= 363.889160, Training Accuracy= 0.96094\n",
      "957\n",
      "Iter 122496, Minibatch Loss= 136.673401, Training Accuracy= 0.99219\n",
      "958\n",
      "Iter 122624, Minibatch Loss= 166.196075, Training Accuracy= 0.97656\n",
      "959\n",
      "Iter 122752, Minibatch Loss= 418.298737, Training Accuracy= 0.95312\n",
      "960\n",
      "Iter 122880, Minibatch Loss= 47.456314, Training Accuracy= 0.98438\n",
      "961\n",
      "Iter 123008, Minibatch Loss= 160.115143, Training Accuracy= 0.96875\n",
      "962\n",
      "Iter 123136, Minibatch Loss= 417.615173, Training Accuracy= 0.96875\n",
      "963\n",
      "Iter 123264, Minibatch Loss= 186.850952, Training Accuracy= 0.97656\n",
      "964\n",
      "Iter 123392, Minibatch Loss= 284.035492, Training Accuracy= 0.96875\n",
      "965\n",
      "Iter 123520, Minibatch Loss= 175.407394, Training Accuracy= 0.94531\n",
      "966\n",
      "Iter 123648, Minibatch Loss= 198.542847, Training Accuracy= 0.96094\n",
      "967\n",
      "Iter 123776, Minibatch Loss= 196.943649, Training Accuracy= 0.96094\n",
      "968\n",
      "Iter 123904, Minibatch Loss= 116.995651, Training Accuracy= 0.98438\n",
      "969\n",
      "Iter 124032, Minibatch Loss= 204.387360, Training Accuracy= 0.96094\n",
      "970\n",
      "Iter 124160, Minibatch Loss= 194.224304, Training Accuracy= 0.95312\n",
      "971\n",
      "Iter 124288, Minibatch Loss= 265.960419, Training Accuracy= 0.96875\n",
      "972\n",
      "Iter 124416, Minibatch Loss= 284.282501, Training Accuracy= 0.96875\n",
      "973\n",
      "Iter 124544, Minibatch Loss= 186.187637, Training Accuracy= 0.96875\n",
      "974\n",
      "Iter 124672, Minibatch Loss= 270.086823, Training Accuracy= 0.96094\n",
      "975\n",
      "Iter 124800, Minibatch Loss= 324.477539, Training Accuracy= 0.96875\n",
      "976\n",
      "Iter 124928, Minibatch Loss= 501.881012, Training Accuracy= 0.94531\n",
      "977\n",
      "Iter 125056, Minibatch Loss= 377.194550, Training Accuracy= 0.96094\n",
      "978\n",
      "Iter 125184, Minibatch Loss= 208.437164, Training Accuracy= 0.98438\n",
      "979\n",
      "Iter 125312, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "980\n",
      "Iter 125440, Minibatch Loss= 199.498932, Training Accuracy= 0.96094\n",
      "981\n",
      "Iter 125568, Minibatch Loss= 48.001312, Training Accuracy= 0.98438\n",
      "982\n",
      "Iter 125696, Minibatch Loss= 144.779846, Training Accuracy= 0.97656\n",
      "983\n",
      "Iter 125824, Minibatch Loss= 132.995728, Training Accuracy= 0.96875\n",
      "984\n",
      "Iter 125952, Minibatch Loss= 133.442581, Training Accuracy= 0.96094\n",
      "985\n",
      "Iter 126080, Minibatch Loss= 36.464844, Training Accuracy= 0.97656\n",
      "986\n",
      "Iter 126208, Minibatch Loss= 155.834473, Training Accuracy= 0.98438\n",
      "987\n",
      "Iter 126336, Minibatch Loss= 522.561279, Training Accuracy= 0.92969\n",
      "988\n",
      "Iter 126464, Minibatch Loss= 80.394577, Training Accuracy= 0.98438\n",
      "989\n",
      "Iter 126592, Minibatch Loss= 153.322830, Training Accuracy= 0.96094\n",
      "990\n",
      "Iter 126720, Minibatch Loss= 340.140381, Training Accuracy= 0.94531\n",
      "991\n",
      "Iter 126848, Minibatch Loss= 462.096191, Training Accuracy= 0.92969\n",
      "992\n",
      "Iter 126976, Minibatch Loss= 157.777512, Training Accuracy= 0.98438\n",
      "993\n",
      "Iter 127104, Minibatch Loss= 144.626450, Training Accuracy= 0.96875\n",
      "994\n",
      "Iter 127232, Minibatch Loss= 298.626465, Training Accuracy= 0.94531\n",
      "995\n",
      "Iter 127360, Minibatch Loss= 65.281418, Training Accuracy= 0.99219\n",
      "996\n",
      "Iter 127488, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "997\n",
      "Iter 127616, Minibatch Loss= 142.216705, Training Accuracy= 0.98438\n",
      "998\n",
      "Iter 127744, Minibatch Loss= 76.701927, Training Accuracy= 0.96875\n",
      "999\n",
      "Iter 127872, Minibatch Loss= 127.498940, Training Accuracy= 0.96875\n",
      "1000\n",
      "Iter 128000, Minibatch Loss= 340.044495, Training Accuracy= 0.95312\n",
      "1001\n",
      "Iter 128128, Minibatch Loss= 280.080566, Training Accuracy= 0.96094\n",
      "1002\n",
      "Iter 128256, Minibatch Loss= 423.292969, Training Accuracy= 0.95312\n",
      "1003\n",
      "Iter 128384, Minibatch Loss= 492.051819, Training Accuracy= 0.92188\n",
      "1004\n",
      "Iter 128512, Minibatch Loss= 286.819763, Training Accuracy= 0.96875\n",
      "1005\n",
      "Iter 128640, Minibatch Loss= 250.354874, Training Accuracy= 0.96094\n",
      "1006\n",
      "Iter 128768, Minibatch Loss= 81.669540, Training Accuracy= 0.96875\n",
      "1007\n",
      "Iter 128896, Minibatch Loss= 397.837433, Training Accuracy= 0.95312\n",
      "1008\n",
      "Iter 129024, Minibatch Loss= 121.591660, Training Accuracy= 0.96094\n",
      "1009\n",
      "Iter 129152, Minibatch Loss= 553.522583, Training Accuracy= 0.96094\n",
      "1010\n",
      "Iter 129280, Minibatch Loss= 240.017181, Training Accuracy= 0.96094\n",
      "1011\n",
      "Iter 129408, Minibatch Loss= 148.339966, Training Accuracy= 0.96875\n",
      "1012\n",
      "Iter 129536, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "1013\n",
      "Iter 129664, Minibatch Loss= 286.322449, Training Accuracy= 0.96875\n",
      "1014\n",
      "Iter 129792, Minibatch Loss= 13.049225, Training Accuracy= 0.99219\n",
      "1015\n",
      "Iter 129920, Minibatch Loss= 382.087280, Training Accuracy= 0.94531\n",
      "1016\n",
      "Iter 130048, Minibatch Loss= 345.582916, Training Accuracy= 0.96094\n",
      "1017\n",
      "Iter 130176, Minibatch Loss= 482.189087, Training Accuracy= 0.93750\n",
      "1018\n",
      "Iter 130304, Minibatch Loss= 62.269730, Training Accuracy= 0.96875\n",
      "1019\n",
      "Iter 130432, Minibatch Loss= 239.539413, Training Accuracy= 0.96094\n",
      "1020\n",
      "Iter 130560, Minibatch Loss= 111.142944, Training Accuracy= 0.96875\n",
      "1021\n",
      "Iter 130688, Minibatch Loss= 309.572113, Training Accuracy= 0.97656\n",
      "1022\n",
      "Iter 130816, Minibatch Loss= 161.260712, Training Accuracy= 0.96875\n",
      "1023\n",
      "Iter 130944, Minibatch Loss= 437.907410, Training Accuracy= 0.95312\n",
      "1024\n",
      "Iter 131072, Minibatch Loss= 354.694580, Training Accuracy= 0.98438\n",
      "1025\n",
      "Iter 131200, Minibatch Loss= 181.352371, Training Accuracy= 0.96094\n",
      "1026\n",
      "Iter 131328, Minibatch Loss= 412.984253, Training Accuracy= 0.95312\n",
      "1027\n",
      "Iter 131456, Minibatch Loss= 97.593704, Training Accuracy= 0.96094\n",
      "1028\n",
      "Iter 131584, Minibatch Loss= 216.381424, Training Accuracy= 0.96875\n",
      "1029\n",
      "Iter 131712, Minibatch Loss= 281.280457, Training Accuracy= 0.94531\n",
      "1030\n",
      "Iter 131840, Minibatch Loss= 12.601837, Training Accuracy= 0.98438\n",
      "1031\n",
      "Iter 131968, Minibatch Loss= 252.465057, Training Accuracy= 0.96875\n",
      "1032\n",
      "Iter 132096, Minibatch Loss= 207.642517, Training Accuracy= 0.96094\n",
      "1033\n",
      "Iter 132224, Minibatch Loss= 241.912811, Training Accuracy= 0.97656\n",
      "1034\n",
      "Iter 132352, Minibatch Loss= 98.196030, Training Accuracy= 0.99219\n",
      "1035\n",
      "Iter 132480, Minibatch Loss= 89.362877, Training Accuracy= 0.97656\n",
      "1036\n",
      "Iter 132608, Minibatch Loss= 188.237823, Training Accuracy= 0.96094\n",
      "1037\n",
      "Iter 132736, Minibatch Loss= 454.835358, Training Accuracy= 0.92188\n",
      "1038\n",
      "Iter 132864, Minibatch Loss= 85.409355, Training Accuracy= 0.97656\n",
      "1039\n",
      "Iter 132992, Minibatch Loss= 272.092896, Training Accuracy= 0.96875\n",
      "1040\n",
      "Iter 133120, Minibatch Loss= 403.344208, Training Accuracy= 0.96094\n",
      "1041\n",
      "Iter 133248, Minibatch Loss= 158.216690, Training Accuracy= 0.97656\n",
      "1042\n",
      "Iter 133376, Minibatch Loss= 250.701630, Training Accuracy= 0.97656\n",
      "1043\n",
      "Iter 133504, Minibatch Loss= 248.491119, Training Accuracy= 0.96094\n",
      "1044\n",
      "Iter 133632, Minibatch Loss= 269.676941, Training Accuracy= 0.96875\n",
      "1045\n",
      "Iter 133760, Minibatch Loss= 98.432388, Training Accuracy= 0.97656\n",
      "1046\n",
      "Iter 133888, Minibatch Loss= 278.893799, Training Accuracy= 0.96094\n",
      "1047\n",
      "Iter 134016, Minibatch Loss= 118.243179, Training Accuracy= 0.96875\n",
      "1048\n",
      "Iter 134144, Minibatch Loss= 122.956276, Training Accuracy= 0.97656\n",
      "1049\n",
      "Iter 134272, Minibatch Loss= 158.826996, Training Accuracy= 0.96875\n",
      "1050\n",
      "Iter 134400, Minibatch Loss= 121.259712, Training Accuracy= 0.97656\n",
      "1051\n",
      "Iter 134528, Minibatch Loss= 97.534836, Training Accuracy= 0.97656\n",
      "1052\n",
      "Iter 134656, Minibatch Loss= 607.759827, Training Accuracy= 0.91406\n",
      "1053\n",
      "Iter 134784, Minibatch Loss= 229.933472, Training Accuracy= 0.96875\n",
      "1054\n",
      "Iter 134912, Minibatch Loss= 104.018486, Training Accuracy= 0.98438\n",
      "1055\n",
      "Iter 135040, Minibatch Loss= 343.165344, Training Accuracy= 0.94531\n",
      "1056\n",
      "Iter 135168, Minibatch Loss= 290.479156, Training Accuracy= 0.97656\n",
      "1057\n",
      "Iter 135296, Minibatch Loss= 187.411484, Training Accuracy= 0.99219\n",
      "1058\n",
      "Iter 135424, Minibatch Loss= 297.271027, Training Accuracy= 0.96875\n",
      "1059\n",
      "Iter 135552, Minibatch Loss= 127.102127, Training Accuracy= 0.95312\n",
      "1060\n",
      "Iter 135680, Minibatch Loss= 206.958618, Training Accuracy= 0.95312\n",
      "1061\n",
      "Iter 135808, Minibatch Loss= 141.136093, Training Accuracy= 0.96875\n",
      "1062\n",
      "Iter 135936, Minibatch Loss= 185.526230, Training Accuracy= 0.95312\n",
      "1063\n",
      "Iter 136064, Minibatch Loss= 115.322914, Training Accuracy= 0.97656\n",
      "1064\n",
      "Iter 136192, Minibatch Loss= 293.411377, Training Accuracy= 0.96094\n",
      "1065\n",
      "Iter 136320, Minibatch Loss= 72.123413, Training Accuracy= 0.98438\n",
      "1066\n",
      "Iter 136448, Minibatch Loss= 483.244781, Training Accuracy= 0.93750\n",
      "1067\n",
      "Iter 136576, Minibatch Loss= 275.147797, Training Accuracy= 0.96875\n",
      "1068\n",
      "Iter 136704, Minibatch Loss= 17.521393, Training Accuracy= 0.97656\n",
      "1069\n",
      "Iter 136832, Minibatch Loss= 22.642578, Training Accuracy= 0.98438\n",
      "1070\n",
      "Iter 136960, Minibatch Loss= 360.451996, Training Accuracy= 0.92969\n",
      "1071\n",
      "Iter 137088, Minibatch Loss= 62.406799, Training Accuracy= 0.98438\n",
      "1072\n",
      "Iter 137216, Minibatch Loss= 70.027115, Training Accuracy= 0.98438\n",
      "1073\n",
      "Iter 137344, Minibatch Loss= 258.232025, Training Accuracy= 0.96875\n",
      "1074\n",
      "Iter 137472, Minibatch Loss= 280.129395, Training Accuracy= 0.96875\n",
      "1075\n",
      "Iter 137600, Minibatch Loss= 169.009232, Training Accuracy= 0.98438\n",
      "1076\n",
      "Iter 137728, Minibatch Loss= 281.628662, Training Accuracy= 0.94531\n",
      "1077\n",
      "Iter 137856, Minibatch Loss= 335.198975, Training Accuracy= 0.95312\n",
      "1078\n",
      "Iter 137984, Minibatch Loss= 12.036835, Training Accuracy= 0.99219\n",
      "1079\n",
      "Iter 138112, Minibatch Loss= 114.556480, Training Accuracy= 0.95312\n",
      "1080\n",
      "Iter 138240, Minibatch Loss= 122.253220, Training Accuracy= 0.94531\n",
      "1081\n",
      "Iter 138368, Minibatch Loss= 129.781464, Training Accuracy= 0.96094\n",
      "1082\n",
      "Iter 138496, Minibatch Loss= 178.205887, Training Accuracy= 0.97656\n",
      "1083\n",
      "Iter 138624, Minibatch Loss= 116.284576, Training Accuracy= 0.98438\n",
      "1084\n",
      "Iter 138752, Minibatch Loss= 182.941986, Training Accuracy= 0.97656\n",
      "1085\n",
      "Iter 138880, Minibatch Loss= 230.219101, Training Accuracy= 0.95312\n",
      "1086\n",
      "Iter 139008, Minibatch Loss= 368.913940, Training Accuracy= 0.93750\n",
      "1087\n",
      "Iter 139136, Minibatch Loss= 297.096252, Training Accuracy= 0.96094\n",
      "1088\n",
      "Iter 139264, Minibatch Loss= 78.495789, Training Accuracy= 0.97656\n",
      "1089\n",
      "Iter 139392, Minibatch Loss= 86.745529, Training Accuracy= 0.96875\n",
      "1090\n",
      "Iter 139520, Minibatch Loss= 247.283020, Training Accuracy= 0.96094\n",
      "1091\n",
      "Iter 139648, Minibatch Loss= 142.668335, Training Accuracy= 0.97656\n",
      "1092\n",
      "Iter 139776, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "1093\n",
      "Iter 139904, Minibatch Loss= 110.499184, Training Accuracy= 0.96094\n",
      "1094\n",
      "Iter 140032, Minibatch Loss= 181.300369, Training Accuracy= 0.97656\n",
      "1095\n",
      "Iter 140160, Minibatch Loss= 416.386230, Training Accuracy= 0.94531\n",
      "1096\n",
      "Iter 140288, Minibatch Loss= 221.144531, Training Accuracy= 0.97656\n",
      "1097\n",
      "Iter 140416, Minibatch Loss= 6.514053, Training Accuracy= 0.98438\n",
      "1098\n",
      "Iter 140544, Minibatch Loss= 166.473831, Training Accuracy= 0.96875\n",
      "1099\n",
      "Iter 140672, Minibatch Loss= 654.525635, Training Accuracy= 0.96875\n",
      "1100\n",
      "Iter 140800, Minibatch Loss= 242.805817, Training Accuracy= 0.95312\n",
      "1101\n",
      "Iter 140928, Minibatch Loss= 146.261261, Training Accuracy= 0.96875\n",
      "1102\n",
      "Iter 141056, Minibatch Loss= 426.883423, Training Accuracy= 0.95312\n",
      "1103\n",
      "Iter 141184, Minibatch Loss= 81.250671, Training Accuracy= 0.96875\n",
      "1104\n",
      "Iter 141312, Minibatch Loss= 283.542114, Training Accuracy= 0.96094\n",
      "1105\n",
      "Iter 141440, Minibatch Loss= 152.084946, Training Accuracy= 0.97656\n",
      "1106\n",
      "Iter 141568, Minibatch Loss= 234.217148, Training Accuracy= 0.94531\n",
      "1107\n",
      "Iter 141696, Minibatch Loss= 278.118530, Training Accuracy= 0.96094\n",
      "1108\n",
      "Iter 141824, Minibatch Loss= 210.241669, Training Accuracy= 0.97656\n",
      "1109\n",
      "Iter 141952, Minibatch Loss= 235.880585, Training Accuracy= 0.95312\n",
      "1110\n",
      "Iter 142080, Minibatch Loss= 29.683632, Training Accuracy= 0.98438\n",
      "1111\n",
      "Iter 142208, Minibatch Loss= 214.930710, Training Accuracy= 0.96094\n",
      "1112\n",
      "Iter 142336, Minibatch Loss= 139.939346, Training Accuracy= 0.98438\n",
      "1113\n",
      "Iter 142464, Minibatch Loss= 372.281494, Training Accuracy= 0.96875\n",
      "1114\n",
      "Iter 142592, Minibatch Loss= 95.415024, Training Accuracy= 0.96875\n",
      "1115\n",
      "Iter 142720, Minibatch Loss= 14.400116, Training Accuracy= 0.99219\n",
      "1116\n",
      "Iter 142848, Minibatch Loss= 82.637161, Training Accuracy= 0.98438\n",
      "1117\n",
      "Iter 142976, Minibatch Loss= 273.391846, Training Accuracy= 0.95312\n",
      "1118\n",
      "Iter 143104, Minibatch Loss= 15.761955, Training Accuracy= 0.99219\n",
      "1119\n",
      "Iter 143232, Minibatch Loss= 416.784790, Training Accuracy= 0.92969\n",
      "1120\n",
      "Iter 143360, Minibatch Loss= 212.724945, Training Accuracy= 0.97656\n",
      "1121\n",
      "Iter 143488, Minibatch Loss= 25.987366, Training Accuracy= 0.99219\n",
      "1122\n",
      "Iter 143616, Minibatch Loss= 436.207581, Training Accuracy= 0.96875\n",
      "1123\n",
      "Iter 143744, Minibatch Loss= 2.437897, Training Accuracy= 0.99219\n",
      "1124\n",
      "Iter 143872, Minibatch Loss= 239.783478, Training Accuracy= 0.96094\n",
      "1125\n",
      "Iter 144000, Minibatch Loss= 821.598877, Training Accuracy= 0.96094\n",
      "1126\n",
      "Iter 144128, Minibatch Loss= 174.487747, Training Accuracy= 0.97656\n",
      "1127\n",
      "Iter 144256, Minibatch Loss= 107.893799, Training Accuracy= 0.97656\n",
      "1128\n",
      "Iter 144384, Minibatch Loss= 131.227371, Training Accuracy= 0.96875\n",
      "1129\n",
      "Iter 144512, Minibatch Loss= 231.903839, Training Accuracy= 0.96875\n",
      "1130\n",
      "Iter 144640, Minibatch Loss= 346.203430, Training Accuracy= 0.93750\n",
      "1131\n",
      "Iter 144768, Minibatch Loss= 282.457825, Training Accuracy= 0.96094\n",
      "1132\n",
      "Iter 144896, Minibatch Loss= 499.125153, Training Accuracy= 0.96875\n",
      "1133\n",
      "Iter 145024, Minibatch Loss= 455.775177, Training Accuracy= 0.96094\n",
      "1134\n",
      "Iter 145152, Minibatch Loss= 587.523254, Training Accuracy= 0.92969\n",
      "1135\n",
      "Iter 145280, Minibatch Loss= 248.644669, Training Accuracy= 0.96094\n",
      "1136\n",
      "Iter 145408, Minibatch Loss= 133.852478, Training Accuracy= 0.97656\n",
      "1137\n",
      "Iter 145536, Minibatch Loss= 574.770386, Training Accuracy= 0.94531\n",
      "1138\n",
      "Iter 145664, Minibatch Loss= 163.148376, Training Accuracy= 0.97656\n",
      "1139\n",
      "Iter 145792, Minibatch Loss= 301.940887, Training Accuracy= 0.96094\n",
      "1140\n",
      "Iter 145920, Minibatch Loss= 277.317413, Training Accuracy= 0.96094\n",
      "1141\n",
      "Iter 146048, Minibatch Loss= 75.146820, Training Accuracy= 0.97656\n",
      "1142\n",
      "Iter 146176, Minibatch Loss= 335.039948, Training Accuracy= 0.95312\n",
      "1143\n",
      "Iter 146304, Minibatch Loss= 310.858093, Training Accuracy= 0.97656\n",
      "1144\n",
      "Iter 146432, Minibatch Loss= 46.801033, Training Accuracy= 0.98438\n",
      "1145\n",
      "Iter 146560, Minibatch Loss= 166.608337, Training Accuracy= 0.96094\n",
      "1146\n",
      "Iter 146688, Minibatch Loss= 88.412971, Training Accuracy= 0.96875\n",
      "1147\n",
      "Iter 146816, Minibatch Loss= 132.634293, Training Accuracy= 0.96875\n",
      "1148\n",
      "Iter 146944, Minibatch Loss= 170.762619, Training Accuracy= 0.96875\n",
      "1149\n",
      "Iter 147072, Minibatch Loss= 478.967987, Training Accuracy= 0.92188\n",
      "1150\n",
      "Iter 147200, Minibatch Loss= 122.872253, Training Accuracy= 0.97656\n",
      "1151\n",
      "Iter 147328, Minibatch Loss= 227.291992, Training Accuracy= 0.95312\n",
      "1152\n",
      "Iter 147456, Minibatch Loss= 55.990707, Training Accuracy= 0.98438\n",
      "1153\n",
      "Iter 147584, Minibatch Loss= 47.418716, Training Accuracy= 0.98438\n",
      "1154\n",
      "Iter 147712, Minibatch Loss= 432.863251, Training Accuracy= 0.95312\n",
      "1155\n",
      "Iter 147840, Minibatch Loss= 535.143799, Training Accuracy= 0.93750\n",
      "1156\n",
      "Iter 147968, Minibatch Loss= 140.502258, Training Accuracy= 0.98438\n",
      "1157\n",
      "Iter 148096, Minibatch Loss= 368.007202, Training Accuracy= 0.94531\n",
      "1158\n",
      "Iter 148224, Minibatch Loss= 188.575729, Training Accuracy= 0.96875\n",
      "1159\n",
      "Iter 148352, Minibatch Loss= 284.775391, Training Accuracy= 0.96094\n",
      "1160\n",
      "Iter 148480, Minibatch Loss= 22.842758, Training Accuracy= 0.99219\n",
      "1161\n",
      "Iter 148608, Minibatch Loss= 304.782928, Training Accuracy= 0.95312\n",
      "1162\n",
      "Iter 148736, Minibatch Loss= 261.563965, Training Accuracy= 0.96875\n",
      "1163\n",
      "Iter 148864, Minibatch Loss= 208.076553, Training Accuracy= 0.95312\n",
      "1164\n",
      "Iter 148992, Minibatch Loss= 83.226532, Training Accuracy= 0.98438\n",
      "1165\n",
      "Iter 149120, Minibatch Loss= 239.573944, Training Accuracy= 0.94531\n",
      "1166\n",
      "Iter 149248, Minibatch Loss= 12.094028, Training Accuracy= 0.99219\n",
      "1167\n",
      "Iter 149376, Minibatch Loss= 21.838448, Training Accuracy= 0.98438\n",
      "1168\n",
      "Iter 149504, Minibatch Loss= 210.543655, Training Accuracy= 0.97656\n",
      "1169\n",
      "Iter 149632, Minibatch Loss= 546.974854, Training Accuracy= 0.94531\n",
      "1170\n",
      "Iter 149760, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "1171\n",
      "Iter 149888, Minibatch Loss= 186.114822, Training Accuracy= 0.96875\n",
      "1172\n",
      "Iter 150016, Minibatch Loss= 134.520493, Training Accuracy= 0.98438\n",
      "1173\n",
      "Iter 150144, Minibatch Loss= 202.905472, Training Accuracy= 0.96094\n",
      "1174\n",
      "Iter 150272, Minibatch Loss= 74.521088, Training Accuracy= 0.98438\n",
      "1175\n",
      "Iter 150400, Minibatch Loss= 293.858795, Training Accuracy= 0.96094\n",
      "1176\n",
      "Iter 150528, Minibatch Loss= 50.763580, Training Accuracy= 0.99219\n",
      "1177\n",
      "Iter 150656, Minibatch Loss= 99.960617, Training Accuracy= 0.98438\n",
      "1178\n",
      "Iter 150784, Minibatch Loss= 79.326462, Training Accuracy= 0.97656\n",
      "1179\n",
      "Iter 150912, Minibatch Loss= 99.209885, Training Accuracy= 0.96094\n",
      "1180\n",
      "Iter 151040, Minibatch Loss= 381.931519, Training Accuracy= 0.96094\n",
      "1181\n",
      "Iter 151168, Minibatch Loss= 240.525650, Training Accuracy= 0.97656\n",
      "1182\n",
      "Iter 151296, Minibatch Loss= 411.532166, Training Accuracy= 0.95312\n",
      "1183\n",
      "Iter 151424, Minibatch Loss= 251.155228, Training Accuracy= 0.96875\n",
      "1184\n",
      "Iter 151552, Minibatch Loss= 437.490082, Training Accuracy= 0.97656\n",
      "1185\n",
      "Iter 151680, Minibatch Loss= 30.643402, Training Accuracy= 0.98438\n",
      "1186\n",
      "Iter 151808, Minibatch Loss= 278.876495, Training Accuracy= 0.92969\n",
      "1187\n",
      "Iter 151936, Minibatch Loss= 80.603050, Training Accuracy= 0.98438\n",
      "1188\n",
      "Iter 152064, Minibatch Loss= 103.744637, Training Accuracy= 0.98438\n",
      "1189\n",
      "Iter 152192, Minibatch Loss= 147.490204, Training Accuracy= 0.97656\n",
      "1190\n",
      "Iter 152320, Minibatch Loss= 85.562302, Training Accuracy= 0.98438\n",
      "1191\n",
      "Iter 152448, Minibatch Loss= 422.898193, Training Accuracy= 0.94531\n",
      "1192\n",
      "Iter 152576, Minibatch Loss= 157.094666, Training Accuracy= 0.96875\n",
      "1193\n",
      "Iter 152704, Minibatch Loss= 443.779846, Training Accuracy= 0.95312\n",
      "1194\n",
      "Iter 152832, Minibatch Loss= 359.446503, Training Accuracy= 0.94531\n",
      "1195\n",
      "Iter 152960, Minibatch Loss= 38.328613, Training Accuracy= 0.96875\n",
      "1196\n",
      "Iter 153088, Minibatch Loss= 151.416412, Training Accuracy= 0.97656\n",
      "1197\n",
      "Iter 153216, Minibatch Loss= 29.023735, Training Accuracy= 0.98438\n",
      "1198\n",
      "Iter 153344, Minibatch Loss= 183.084900, Training Accuracy= 0.96875\n",
      "1199\n",
      "Iter 153472, Minibatch Loss= 89.774490, Training Accuracy= 0.99219\n",
      "1200\n",
      "Iter 153600, Minibatch Loss= 166.909714, Training Accuracy= 0.97656\n",
      "1201\n",
      "Iter 153728, Minibatch Loss= 141.518890, Training Accuracy= 0.96875\n",
      "1202\n",
      "Iter 153856, Minibatch Loss= 13.055069, Training Accuracy= 0.98438\n",
      "1203\n",
      "Iter 153984, Minibatch Loss= 482.272034, Training Accuracy= 0.95312\n",
      "1204\n",
      "Iter 154112, Minibatch Loss= 561.196899, Training Accuracy= 0.95312\n",
      "1205\n",
      "Iter 154240, Minibatch Loss= 150.982819, Training Accuracy= 0.97656\n",
      "1206\n",
      "Iter 154368, Minibatch Loss= 47.363876, Training Accuracy= 0.98438\n",
      "1207\n",
      "Iter 154496, Minibatch Loss= 106.624992, Training Accuracy= 0.96094\n",
      "1208\n",
      "Iter 154624, Minibatch Loss= 137.204163, Training Accuracy= 0.96094\n",
      "1209\n",
      "Iter 154752, Minibatch Loss= 64.754105, Training Accuracy= 0.97656\n",
      "1210\n",
      "Iter 154880, Minibatch Loss= 154.694061, Training Accuracy= 0.98438\n",
      "1211\n",
      "Iter 155008, Minibatch Loss= 159.897095, Training Accuracy= 0.95312\n",
      "1212\n",
      "Iter 155136, Minibatch Loss= 259.494598, Training Accuracy= 0.96875\n",
      "1213\n",
      "Iter 155264, Minibatch Loss= 197.129608, Training Accuracy= 0.96875\n",
      "1214\n",
      "Iter 155392, Minibatch Loss= 217.735474, Training Accuracy= 0.97656\n",
      "1215\n",
      "Iter 155520, Minibatch Loss= 388.392273, Training Accuracy= 0.93750\n",
      "1216\n",
      "Iter 155648, Minibatch Loss= 170.876709, Training Accuracy= 0.95312\n",
      "1217\n",
      "Iter 155776, Minibatch Loss= 252.008957, Training Accuracy= 0.97656\n",
      "1218\n",
      "Iter 155904, Minibatch Loss= 251.481644, Training Accuracy= 0.97656\n",
      "1219\n",
      "Iter 156032, Minibatch Loss= 391.569092, Training Accuracy= 0.95312\n",
      "1220\n",
      "Iter 156160, Minibatch Loss= 453.689148, Training Accuracy= 0.97656\n",
      "1221\n",
      "Iter 156288, Minibatch Loss= 137.157196, Training Accuracy= 0.95312\n",
      "1222\n",
      "Iter 156416, Minibatch Loss= 165.627472, Training Accuracy= 0.96875\n",
      "1223\n",
      "Iter 156544, Minibatch Loss= 61.219498, Training Accuracy= 0.97656\n",
      "1224\n",
      "Iter 156672, Minibatch Loss= 249.655060, Training Accuracy= 0.95312\n",
      "1225\n",
      "Iter 156800, Minibatch Loss= 303.840515, Training Accuracy= 0.95312\n",
      "1226\n",
      "Iter 156928, Minibatch Loss= 122.588257, Training Accuracy= 0.96875\n",
      "1227\n",
      "Iter 157056, Minibatch Loss= 291.838257, Training Accuracy= 0.96094\n",
      "1228\n",
      "Iter 157184, Minibatch Loss= 154.503723, Training Accuracy= 0.98438\n",
      "1229\n",
      "Iter 157312, Minibatch Loss= 194.849136, Training Accuracy= 0.96875\n",
      "1230\n",
      "Iter 157440, Minibatch Loss= 207.645935, Training Accuracy= 0.97656\n",
      "1231\n",
      "Iter 157568, Minibatch Loss= 379.412567, Training Accuracy= 0.95312\n",
      "1232\n",
      "Iter 157696, Minibatch Loss= 41.653030, Training Accuracy= 0.99219\n",
      "1233\n",
      "Iter 157824, Minibatch Loss= 591.919495, Training Accuracy= 0.93750\n",
      "1234\n",
      "Iter 157952, Minibatch Loss= 360.873474, Training Accuracy= 0.96094\n",
      "1235\n",
      "Iter 158080, Minibatch Loss= 318.011047, Training Accuracy= 0.95312\n",
      "1236\n",
      "Iter 158208, Minibatch Loss= 46.164772, Training Accuracy= 0.98438\n",
      "1237\n",
      "Iter 158336, Minibatch Loss= 139.762360, Training Accuracy= 0.96875\n",
      "1238\n",
      "Iter 158464, Minibatch Loss= 441.596649, Training Accuracy= 0.95312\n",
      "1239\n",
      "Iter 158592, Minibatch Loss= 74.269684, Training Accuracy= 0.97656\n",
      "1240\n",
      "Iter 158720, Minibatch Loss= 5.047089, Training Accuracy= 0.99219\n",
      "1241\n",
      "Iter 158848, Minibatch Loss= 21.236374, Training Accuracy= 0.98438\n",
      "1242\n",
      "Iter 158976, Minibatch Loss= 41.283077, Training Accuracy= 0.99219\n",
      "1243\n",
      "Iter 159104, Minibatch Loss= 137.286057, Training Accuracy= 0.96875\n",
      "1244\n",
      "Iter 159232, Minibatch Loss= 286.793701, Training Accuracy= 0.96875\n",
      "1245\n",
      "Iter 159360, Minibatch Loss= 485.400757, Training Accuracy= 0.92969\n",
      "1246\n",
      "Iter 159488, Minibatch Loss= 163.665085, Training Accuracy= 0.96875\n",
      "1247\n",
      "Iter 159616, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "1248\n",
      "Iter 159744, Minibatch Loss= 135.697342, Training Accuracy= 0.96875\n",
      "1249\n",
      "Iter 159872, Minibatch Loss= 96.008247, Training Accuracy= 0.97656\n",
      "1250\n",
      "Iter 160000, Minibatch Loss= 274.803894, Training Accuracy= 0.92969\n",
      "1251\n",
      "Iter 160128, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "1252\n",
      "Iter 160256, Minibatch Loss= 187.382874, Training Accuracy= 0.96875\n",
      "1253\n",
      "Iter 160384, Minibatch Loss= 227.600037, Training Accuracy= 0.96094\n",
      "1254\n",
      "Iter 160512, Minibatch Loss= 53.903030, Training Accuracy= 0.97656\n",
      "1255\n",
      "Iter 160640, Minibatch Loss= 162.703033, Training Accuracy= 0.96875\n",
      "1256\n",
      "Iter 160768, Minibatch Loss= 180.012177, Training Accuracy= 0.96875\n",
      "1257\n",
      "Iter 160896, Minibatch Loss= 125.768768, Training Accuracy= 0.97656\n",
      "1258\n",
      "Iter 161024, Minibatch Loss= 252.152161, Training Accuracy= 0.95312\n",
      "1259\n",
      "Iter 161152, Minibatch Loss= 132.490662, Training Accuracy= 0.97656\n",
      "1260\n",
      "Iter 161280, Minibatch Loss= 138.404236, Training Accuracy= 0.96094\n",
      "1261\n",
      "Iter 161408, Minibatch Loss= 251.887146, Training Accuracy= 0.97656\n",
      "1262\n",
      "Iter 161536, Minibatch Loss= 124.262909, Training Accuracy= 0.98438\n",
      "1263\n",
      "Iter 161664, Minibatch Loss= 306.043091, Training Accuracy= 0.96875\n",
      "1264\n",
      "Iter 161792, Minibatch Loss= 92.976349, Training Accuracy= 0.98438\n",
      "1265\n",
      "Iter 161920, Minibatch Loss= 215.750427, Training Accuracy= 0.97656\n",
      "1266\n",
      "Iter 162048, Minibatch Loss= 210.035660, Training Accuracy= 0.96094\n",
      "1267\n",
      "Iter 162176, Minibatch Loss= 26.447464, Training Accuracy= 0.99219\n",
      "1268\n",
      "Iter 162304, Minibatch Loss= 296.621887, Training Accuracy= 0.96094\n",
      "1269\n",
      "Iter 162432, Minibatch Loss= 119.686806, Training Accuracy= 0.97656\n",
      "1270\n",
      "Iter 162560, Minibatch Loss= 137.901367, Training Accuracy= 0.98438\n",
      "1271\n",
      "Iter 162688, Minibatch Loss= 102.926895, Training Accuracy= 0.97656\n",
      "1272\n",
      "Iter 162816, Minibatch Loss= 799.182739, Training Accuracy= 0.94531\n",
      "1273\n",
      "Iter 162944, Minibatch Loss= 209.092178, Training Accuracy= 0.96875\n",
      "1274\n",
      "Iter 163072, Minibatch Loss= 112.356491, Training Accuracy= 0.96094\n",
      "1275\n",
      "Iter 163200, Minibatch Loss= 117.885597, Training Accuracy= 0.98438\n",
      "1276\n",
      "Iter 163328, Minibatch Loss= 125.397850, Training Accuracy= 0.98438\n",
      "1277\n",
      "Iter 163456, Minibatch Loss= 168.064697, Training Accuracy= 0.96875\n",
      "1278\n",
      "Iter 163584, Minibatch Loss= 272.860870, Training Accuracy= 0.94531\n",
      "1279\n",
      "Iter 163712, Minibatch Loss= 45.146255, Training Accuracy= 0.99219\n",
      "1280\n",
      "Iter 163840, Minibatch Loss= 605.056396, Training Accuracy= 0.94531\n",
      "1281\n",
      "Iter 163968, Minibatch Loss= 230.129669, Training Accuracy= 0.96094\n",
      "1282\n",
      "Iter 164096, Minibatch Loss= 360.393433, Training Accuracy= 0.95312\n",
      "1283\n",
      "Iter 164224, Minibatch Loss= 77.635994, Training Accuracy= 0.96875\n",
      "1284\n",
      "Iter 164352, Minibatch Loss= 160.576492, Training Accuracy= 0.97656\n",
      "1285\n",
      "Iter 164480, Minibatch Loss= 209.978638, Training Accuracy= 0.96875\n",
      "1286\n",
      "Iter 164608, Minibatch Loss= 254.976364, Training Accuracy= 0.96094\n",
      "1287\n",
      "Iter 164736, Minibatch Loss= 48.223427, Training Accuracy= 0.98438\n",
      "1288\n",
      "Iter 164864, Minibatch Loss= 100.535294, Training Accuracy= 0.98438\n",
      "1289\n",
      "Iter 164992, Minibatch Loss= 250.750931, Training Accuracy= 0.96094\n",
      "1290\n",
      "Iter 165120, Minibatch Loss= 95.054008, Training Accuracy= 0.97656\n",
      "1291\n",
      "Iter 165248, Minibatch Loss= 144.936859, Training Accuracy= 0.96875\n",
      "1292\n",
      "Iter 165376, Minibatch Loss= 93.887939, Training Accuracy= 0.96875\n",
      "1293\n",
      "Iter 165504, Minibatch Loss= 34.713348, Training Accuracy= 0.98438\n",
      "1294\n",
      "Iter 165632, Minibatch Loss= 93.491386, Training Accuracy= 0.98438\n",
      "1295\n",
      "Iter 165760, Minibatch Loss= 94.944771, Training Accuracy= 0.96094\n",
      "1296\n",
      "Iter 165888, Minibatch Loss= 438.817413, Training Accuracy= 0.95312\n",
      "1297\n",
      "Iter 166016, Minibatch Loss= 134.261230, Training Accuracy= 0.96094\n",
      "1298\n",
      "Iter 166144, Minibatch Loss= 122.766068, Training Accuracy= 0.96875\n",
      "1299\n",
      "Iter 166272, Minibatch Loss= 68.324234, Training Accuracy= 0.98438\n",
      "1300\n",
      "Iter 166400, Minibatch Loss= 130.432861, Training Accuracy= 0.97656\n",
      "1301\n",
      "Iter 166528, Minibatch Loss= 14.082764, Training Accuracy= 0.99219\n",
      "1302\n",
      "Iter 166656, Minibatch Loss= 40.882080, Training Accuracy= 0.98438\n",
      "1303\n",
      "Iter 166784, Minibatch Loss= 113.594124, Training Accuracy= 0.96875\n",
      "1304\n",
      "Iter 166912, Minibatch Loss= 225.528320, Training Accuracy= 0.96875\n",
      "1305\n",
      "Iter 167040, Minibatch Loss= 339.978546, Training Accuracy= 0.94531\n",
      "1306\n",
      "Iter 167168, Minibatch Loss= 131.639526, Training Accuracy= 0.97656\n",
      "1307\n",
      "Iter 167296, Minibatch Loss= 59.702652, Training Accuracy= 0.98438\n",
      "1308\n",
      "Iter 167424, Minibatch Loss= 159.326935, Training Accuracy= 0.98438\n",
      "1309\n",
      "Iter 167552, Minibatch Loss= 322.116333, Training Accuracy= 0.94531\n",
      "1310\n",
      "Iter 167680, Minibatch Loss= 67.741028, Training Accuracy= 0.97656\n",
      "1311\n",
      "Iter 167808, Minibatch Loss= 91.618393, Training Accuracy= 0.96875\n",
      "1312\n",
      "Iter 167936, Minibatch Loss= 145.804901, Training Accuracy= 0.96875\n",
      "1313\n",
      "Iter 168064, Minibatch Loss= 9.055267, Training Accuracy= 0.99219\n",
      "1314\n",
      "Iter 168192, Minibatch Loss= 44.300873, Training Accuracy= 0.98438\n",
      "1315\n",
      "Iter 168320, Minibatch Loss= 197.926941, Training Accuracy= 0.98438\n",
      "1316\n",
      "Iter 168448, Minibatch Loss= 301.295776, Training Accuracy= 0.95312\n",
      "1317\n",
      "Iter 168576, Minibatch Loss= 206.642120, Training Accuracy= 0.96094\n",
      "1318\n",
      "Iter 168704, Minibatch Loss= 85.355545, Training Accuracy= 0.96875\n",
      "1319\n",
      "Iter 168832, Minibatch Loss= 15.923210, Training Accuracy= 0.97656\n",
      "1320\n",
      "Iter 168960, Minibatch Loss= 148.176987, Training Accuracy= 0.96875\n",
      "1321\n",
      "Iter 169088, Minibatch Loss= 30.182190, Training Accuracy= 0.99219\n",
      "1322\n",
      "Iter 169216, Minibatch Loss= 79.588982, Training Accuracy= 0.97656\n",
      "1323\n",
      "Iter 169344, Minibatch Loss= 221.281586, Training Accuracy= 0.98438\n",
      "1324\n",
      "Iter 169472, Minibatch Loss= 9.142838, Training Accuracy= 0.99219\n",
      "1325\n",
      "Iter 169600, Minibatch Loss= 85.339539, Training Accuracy= 0.96875\n",
      "1326\n",
      "Iter 169728, Minibatch Loss= 105.391632, Training Accuracy= 0.96875\n",
      "1327\n",
      "Iter 169856, Minibatch Loss= 140.898163, Training Accuracy= 0.97656\n",
      "1328\n",
      "Iter 169984, Minibatch Loss= 153.210907, Training Accuracy= 0.96875\n",
      "1329\n",
      "Iter 170112, Minibatch Loss= 115.664108, Training Accuracy= 0.97656\n",
      "1330\n",
      "Iter 170240, Minibatch Loss= 31.663414, Training Accuracy= 0.98438\n",
      "1331\n",
      "Iter 170368, Minibatch Loss= 47.116722, Training Accuracy= 0.97656\n",
      "1332\n",
      "Iter 170496, Minibatch Loss= 139.402649, Training Accuracy= 0.98438\n",
      "1333\n",
      "Iter 170624, Minibatch Loss= 68.514641, Training Accuracy= 0.98438\n",
      "1334\n",
      "Iter 170752, Minibatch Loss= 346.746826, Training Accuracy= 0.95312\n",
      "1335\n",
      "Iter 170880, Minibatch Loss= 157.997025, Training Accuracy= 0.96875\n",
      "1336\n",
      "Iter 171008, Minibatch Loss= 130.627548, Training Accuracy= 0.98438\n",
      "1337\n",
      "Iter 171136, Minibatch Loss= 382.238220, Training Accuracy= 0.95312\n",
      "1338\n",
      "Iter 171264, Minibatch Loss= 129.325287, Training Accuracy= 0.97656\n",
      "1339\n",
      "Iter 171392, Minibatch Loss= 100.229050, Training Accuracy= 0.96875\n",
      "1340\n",
      "Iter 171520, Minibatch Loss= 47.120018, Training Accuracy= 0.96875\n",
      "1341\n",
      "Iter 171648, Minibatch Loss= 187.152481, Training Accuracy= 0.96094\n",
      "1342\n",
      "Iter 171776, Minibatch Loss= 43.715851, Training Accuracy= 0.98438\n",
      "1343\n",
      "Iter 171904, Minibatch Loss= 211.151031, Training Accuracy= 0.96875\n",
      "1344\n",
      "Iter 172032, Minibatch Loss= 168.771332, Training Accuracy= 0.96094\n",
      "1345\n",
      "Iter 172160, Minibatch Loss= 126.146324, Training Accuracy= 0.96875\n",
      "1346\n",
      "Iter 172288, Minibatch Loss= 108.186668, Training Accuracy= 0.96875\n",
      "1347\n",
      "Iter 172416, Minibatch Loss= 203.554291, Training Accuracy= 0.96875\n",
      "1348\n",
      "Iter 172544, Minibatch Loss= 223.038712, Training Accuracy= 0.97656\n",
      "1349\n",
      "Iter 172672, Minibatch Loss= 132.938736, Training Accuracy= 0.96094\n",
      "1350\n",
      "Iter 172800, Minibatch Loss= 126.450851, Training Accuracy= 0.96875\n",
      "1351\n",
      "Iter 172928, Minibatch Loss= 217.904694, Training Accuracy= 0.97656\n",
      "1352\n",
      "Iter 173056, Minibatch Loss= 269.619843, Training Accuracy= 0.95312\n",
      "1353\n",
      "Iter 173184, Minibatch Loss= 56.221237, Training Accuracy= 0.97656\n",
      "1354\n",
      "Iter 173312, Minibatch Loss= 0.100037, Training Accuracy= 0.99219\n",
      "1355\n",
      "Iter 173440, Minibatch Loss= 37.559357, Training Accuracy= 0.96875\n",
      "1356\n",
      "Iter 173568, Minibatch Loss= 58.485504, Training Accuracy= 0.99219\n",
      "1357\n",
      "Iter 173696, Minibatch Loss= 366.949097, Training Accuracy= 0.92969\n",
      "1358\n",
      "Iter 173824, Minibatch Loss= 227.702103, Training Accuracy= 0.96875\n",
      "1359\n",
      "Iter 173952, Minibatch Loss= 178.623245, Training Accuracy= 0.96875\n",
      "1360\n",
      "Iter 174080, Minibatch Loss= 258.054871, Training Accuracy= 0.95312\n",
      "1361\n",
      "Iter 174208, Minibatch Loss= 265.355835, Training Accuracy= 0.94531\n",
      "1362\n",
      "Iter 174336, Minibatch Loss= 143.105042, Training Accuracy= 0.96875\n",
      "1363\n",
      "Iter 174464, Minibatch Loss= 127.054428, Training Accuracy= 0.94531\n",
      "1364\n",
      "Iter 174592, Minibatch Loss= 271.463684, Training Accuracy= 0.96875\n",
      "1365\n",
      "Iter 174720, Minibatch Loss= 179.735550, Training Accuracy= 0.96875\n",
      "1366\n",
      "Iter 174848, Minibatch Loss= 223.156357, Training Accuracy= 0.98438\n",
      "1367\n",
      "Iter 174976, Minibatch Loss= 122.918861, Training Accuracy= 0.98438\n",
      "1368\n",
      "Iter 175104, Minibatch Loss= 201.726334, Training Accuracy= 0.96875\n",
      "1369\n",
      "Iter 175232, Minibatch Loss= 189.318069, Training Accuracy= 0.98438\n",
      "1370\n",
      "Iter 175360, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "1371\n",
      "Iter 175488, Minibatch Loss= 270.784119, Training Accuracy= 0.98438\n",
      "1372\n",
      "Iter 175616, Minibatch Loss= 55.777908, Training Accuracy= 0.97656\n",
      "1373\n",
      "Iter 175744, Minibatch Loss= 143.771072, Training Accuracy= 0.98438\n",
      "1374\n",
      "Iter 175872, Minibatch Loss= 79.147095, Training Accuracy= 0.96094\n",
      "1375\n",
      "Iter 176000, Minibatch Loss= 58.551544, Training Accuracy= 0.98438\n",
      "1376\n",
      "Iter 176128, Minibatch Loss= 72.205124, Training Accuracy= 0.97656\n",
      "1377\n",
      "Iter 176256, Minibatch Loss= 2.488129, Training Accuracy= 0.99219\n",
      "1378\n",
      "Iter 176384, Minibatch Loss= 74.137314, Training Accuracy= 0.98438\n",
      "1379\n",
      "Iter 176512, Minibatch Loss= 139.913803, Training Accuracy= 0.97656\n",
      "1380\n",
      "Iter 176640, Minibatch Loss= 240.841949, Training Accuracy= 0.98438\n",
      "1381\n",
      "Iter 176768, Minibatch Loss= 150.177124, Training Accuracy= 0.96875\n",
      "1382\n",
      "Iter 176896, Minibatch Loss= 78.680336, Training Accuracy= 0.98438\n",
      "1383\n",
      "Iter 177024, Minibatch Loss= 37.896713, Training Accuracy= 0.98438\n",
      "1384\n",
      "Iter 177152, Minibatch Loss= 126.875107, Training Accuracy= 0.96875\n",
      "1385\n",
      "Iter 177280, Minibatch Loss= 105.564621, Training Accuracy= 0.97656\n",
      "1386\n",
      "Iter 177408, Minibatch Loss= 83.937965, Training Accuracy= 0.98438\n",
      "1387\n",
      "Iter 177536, Minibatch Loss= 10.566887, Training Accuracy= 0.99219\n",
      "1388\n",
      "Iter 177664, Minibatch Loss= 21.372086, Training Accuracy= 0.99219\n",
      "1389\n",
      "Iter 177792, Minibatch Loss= 39.488609, Training Accuracy= 0.98438\n",
      "1390\n",
      "Iter 177920, Minibatch Loss= 104.358742, Training Accuracy= 0.97656\n",
      "1391\n",
      "Iter 178048, Minibatch Loss= 162.175690, Training Accuracy= 0.96875\n",
      "1392\n",
      "Iter 178176, Minibatch Loss= 357.032654, Training Accuracy= 0.96094\n",
      "1393\n",
      "Iter 178304, Minibatch Loss= 43.165367, Training Accuracy= 0.97656\n",
      "1394\n",
      "Iter 178432, Minibatch Loss= 64.816002, Training Accuracy= 0.96094\n",
      "1395\n",
      "Iter 178560, Minibatch Loss= 353.486877, Training Accuracy= 0.95312\n",
      "1396\n",
      "Iter 178688, Minibatch Loss= 80.958084, Training Accuracy= 0.97656\n",
      "1397\n",
      "Iter 178816, Minibatch Loss= 108.541275, Training Accuracy= 0.98438\n",
      "1398\n",
      "Iter 178944, Minibatch Loss= 195.426514, Training Accuracy= 0.96094\n",
      "1399\n",
      "Iter 179072, Minibatch Loss= 201.360443, Training Accuracy= 0.96875\n",
      "1400\n",
      "Iter 179200, Minibatch Loss= 126.192848, Training Accuracy= 0.96875\n",
      "1401\n",
      "Iter 179328, Minibatch Loss= 132.859589, Training Accuracy= 0.98438\n",
      "1402\n",
      "Iter 179456, Minibatch Loss= 44.916077, Training Accuracy= 0.97656\n",
      "1403\n",
      "Iter 179584, Minibatch Loss= 64.667267, Training Accuracy= 0.99219\n",
      "1404\n",
      "Iter 179712, Minibatch Loss= 8.488113, Training Accuracy= 0.98438\n",
      "1405\n",
      "Iter 179840, Minibatch Loss= 75.659561, Training Accuracy= 0.98438\n",
      "1406\n",
      "Iter 179968, Minibatch Loss= 10.264557, Training Accuracy= 0.99219\n",
      "1407\n",
      "Iter 180096, Minibatch Loss= 43.798553, Training Accuracy= 0.99219\n",
      "1408\n",
      "Iter 180224, Minibatch Loss= 137.672485, Training Accuracy= 0.97656\n",
      "1409\n",
      "Iter 180352, Minibatch Loss= 136.389114, Training Accuracy= 0.96094\n",
      "1410\n",
      "Iter 180480, Minibatch Loss= 27.949982, Training Accuracy= 0.98438\n",
      "1411\n",
      "Iter 180608, Minibatch Loss= 164.494781, Training Accuracy= 0.96094\n",
      "1412\n",
      "Iter 180736, Minibatch Loss= 76.244530, Training Accuracy= 0.98438\n",
      "1413\n",
      "Iter 180864, Minibatch Loss= 65.566841, Training Accuracy= 0.96875\n",
      "1414\n",
      "Iter 180992, Minibatch Loss= 589.013428, Training Accuracy= 0.95312\n",
      "1415\n",
      "Iter 181120, Minibatch Loss= 99.998047, Training Accuracy= 0.99219\n",
      "1416\n",
      "Iter 181248, Minibatch Loss= 166.004898, Training Accuracy= 0.97656\n",
      "1417\n",
      "Iter 181376, Minibatch Loss= 187.892700, Training Accuracy= 0.96875\n",
      "1418\n",
      "Iter 181504, Minibatch Loss= 158.010010, Training Accuracy= 0.96094\n",
      "1419\n",
      "Iter 181632, Minibatch Loss= 135.401886, Training Accuracy= 0.96875\n",
      "1420\n",
      "Iter 181760, Minibatch Loss= 311.867798, Training Accuracy= 0.94531\n",
      "1421\n",
      "Iter 181888, Minibatch Loss= 48.649689, Training Accuracy= 0.98438\n",
      "1422\n",
      "Iter 182016, Minibatch Loss= 118.028259, Training Accuracy= 0.96094\n",
      "1423\n",
      "Iter 182144, Minibatch Loss= 120.258507, Training Accuracy= 0.95312\n",
      "1424\n",
      "Iter 182272, Minibatch Loss= 3.679413, Training Accuracy= 0.99219\n",
      "1425\n",
      "Iter 182400, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "1426\n",
      "Iter 182528, Minibatch Loss= 236.251984, Training Accuracy= 0.94531\n",
      "1427\n",
      "Iter 182656, Minibatch Loss= 113.185112, Training Accuracy= 0.98438\n",
      "1428\n",
      "Iter 182784, Minibatch Loss= 109.331406, Training Accuracy= 0.98438\n",
      "1429\n",
      "Iter 182912, Minibatch Loss= 201.408432, Training Accuracy= 0.95312\n",
      "1430\n",
      "Iter 183040, Minibatch Loss= 75.072510, Training Accuracy= 0.98438\n",
      "1431\n",
      "Iter 183168, Minibatch Loss= 116.109848, Training Accuracy= 0.97656\n",
      "1432\n",
      "Iter 183296, Minibatch Loss= 40.193062, Training Accuracy= 0.97656\n",
      "1433\n",
      "Iter 183424, Minibatch Loss= 101.287750, Training Accuracy= 0.97656\n",
      "1434\n",
      "Iter 183552, Minibatch Loss= 8.288994, Training Accuracy= 0.98438\n",
      "1435\n",
      "Iter 183680, Minibatch Loss= 10.410614, Training Accuracy= 0.99219\n",
      "1436\n",
      "Iter 183808, Minibatch Loss= 172.546631, Training Accuracy= 0.97656\n",
      "1437\n",
      "Iter 183936, Minibatch Loss= 216.045151, Training Accuracy= 0.95312\n",
      "1438\n",
      "Iter 184064, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "1439\n",
      "Iter 184192, Minibatch Loss= 459.485474, Training Accuracy= 0.95312\n",
      "1440\n",
      "Iter 184320, Minibatch Loss= 63.412476, Training Accuracy= 0.97656\n",
      "1441\n",
      "Iter 184448, Minibatch Loss= 145.372253, Training Accuracy= 0.97656\n",
      "1442\n",
      "Iter 184576, Minibatch Loss= 15.029938, Training Accuracy= 0.99219\n",
      "1443\n",
      "Iter 184704, Minibatch Loss= 208.638504, Training Accuracy= 0.98438\n",
      "1444\n",
      "Iter 184832, Minibatch Loss= 91.734734, Training Accuracy= 0.98438\n",
      "1445\n",
      "Iter 184960, Minibatch Loss= 249.725220, Training Accuracy= 0.98438\n",
      "1446\n",
      "Iter 185088, Minibatch Loss= 115.521957, Training Accuracy= 0.97656\n",
      "1447\n",
      "Iter 185216, Minibatch Loss= 55.540138, Training Accuracy= 0.99219\n",
      "1448\n",
      "Iter 185344, Minibatch Loss= 65.303024, Training Accuracy= 0.98438\n",
      "1449\n",
      "Iter 185472, Minibatch Loss= 32.413864, Training Accuracy= 0.98438\n",
      "1450\n",
      "Iter 185600, Minibatch Loss= 399.398682, Training Accuracy= 0.96094\n",
      "1451\n",
      "Iter 185728, Minibatch Loss= 207.309052, Training Accuracy= 0.97656\n",
      "1452\n",
      "Iter 185856, Minibatch Loss= 168.583832, Training Accuracy= 0.97656\n",
      "1453\n",
      "Iter 185984, Minibatch Loss= 168.067291, Training Accuracy= 0.97656\n",
      "1454\n",
      "Iter 186112, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "1455\n",
      "Iter 186240, Minibatch Loss= 97.267319, Training Accuracy= 0.97656\n",
      "1456\n",
      "Iter 186368, Minibatch Loss= 370.847290, Training Accuracy= 0.92969\n",
      "1457\n",
      "Iter 186496, Minibatch Loss= 42.317535, Training Accuracy= 0.97656\n",
      "1458\n",
      "Iter 186624, Minibatch Loss= 182.329056, Training Accuracy= 0.96875\n",
      "1459\n",
      "Iter 186752, Minibatch Loss= 266.958557, Training Accuracy= 0.96094\n",
      "1460\n",
      "Iter 186880, Minibatch Loss= 53.281128, Training Accuracy= 0.97656\n",
      "1461\n",
      "Iter 187008, Minibatch Loss= 152.113800, Training Accuracy= 0.96875\n",
      "1462\n",
      "Iter 187136, Minibatch Loss= 10.079834, Training Accuracy= 0.99219\n",
      "1463\n",
      "Iter 187264, Minibatch Loss= 53.027786, Training Accuracy= 0.98438\n",
      "1464\n",
      "Iter 187392, Minibatch Loss= 167.477631, Training Accuracy= 0.97656\n",
      "1465\n",
      "Iter 187520, Minibatch Loss= 99.208435, Training Accuracy= 0.97656\n",
      "1466\n",
      "Iter 187648, Minibatch Loss= 10.883934, Training Accuracy= 0.99219\n",
      "1467\n",
      "Iter 187776, Minibatch Loss= 57.273415, Training Accuracy= 0.96875\n",
      "1468\n",
      "Iter 187904, Minibatch Loss= 307.046478, Training Accuracy= 0.94531\n",
      "1469\n",
      "Iter 188032, Minibatch Loss= 48.909935, Training Accuracy= 0.98438\n",
      "1470\n",
      "Iter 188160, Minibatch Loss= 218.918610, Training Accuracy= 0.97656\n",
      "1471\n",
      "Iter 188288, Minibatch Loss= 206.432922, Training Accuracy= 0.97656\n",
      "1472\n",
      "Iter 188416, Minibatch Loss= 24.924526, Training Accuracy= 0.98438\n",
      "1473\n",
      "Iter 188544, Minibatch Loss= 141.865112, Training Accuracy= 0.96875\n",
      "1474\n",
      "Iter 188672, Minibatch Loss= 201.468460, Training Accuracy= 0.96875\n",
      "1475\n",
      "Iter 188800, Minibatch Loss= 36.445381, Training Accuracy= 0.97656\n",
      "1476\n",
      "Iter 188928, Minibatch Loss= 174.688385, Training Accuracy= 0.98438\n",
      "1477\n",
      "Iter 189056, Minibatch Loss= 115.166855, Training Accuracy= 0.97656\n",
      "1478\n",
      "Iter 189184, Minibatch Loss= 18.542694, Training Accuracy= 0.97656\n",
      "1479\n",
      "Iter 189312, Minibatch Loss= 168.545029, Training Accuracy= 0.97656\n",
      "1480\n",
      "Iter 189440, Minibatch Loss= 217.419601, Training Accuracy= 0.96875\n",
      "1481\n",
      "Iter 189568, Minibatch Loss= 83.294395, Training Accuracy= 0.99219\n",
      "1482\n",
      "Iter 189696, Minibatch Loss= 85.412941, Training Accuracy= 0.97656\n",
      "1483\n",
      "Iter 189824, Minibatch Loss= 93.037422, Training Accuracy= 0.99219\n",
      "1484\n",
      "Iter 189952, Minibatch Loss= 120.784119, Training Accuracy= 0.97656\n",
      "1485\n",
      "Iter 190080, Minibatch Loss= 51.255325, Training Accuracy= 0.98438\n",
      "1486\n",
      "Iter 190208, Minibatch Loss= 119.020821, Training Accuracy= 0.96094\n",
      "1487\n",
      "Iter 190336, Minibatch Loss= 241.991150, Training Accuracy= 0.96875\n",
      "1488\n",
      "Iter 190464, Minibatch Loss= 448.424072, Training Accuracy= 0.96875\n",
      "1489\n",
      "Iter 190592, Minibatch Loss= 124.511841, Training Accuracy= 0.97656\n",
      "1490\n",
      "Iter 190720, Minibatch Loss= 254.708649, Training Accuracy= 0.95312\n",
      "1491\n",
      "Iter 190848, Minibatch Loss= 15.193008, Training Accuracy= 0.99219\n",
      "1492\n",
      "Iter 190976, Minibatch Loss= 106.829514, Training Accuracy= 0.98438\n",
      "1493\n",
      "Iter 191104, Minibatch Loss= 51.105972, Training Accuracy= 0.98438\n",
      "1494\n",
      "Iter 191232, Minibatch Loss= 99.665489, Training Accuracy= 0.97656\n",
      "1495\n",
      "Iter 191360, Minibatch Loss= 139.495972, Training Accuracy= 0.96875\n",
      "1496\n",
      "Iter 191488, Minibatch Loss= 145.340546, Training Accuracy= 0.96094\n",
      "1497\n",
      "Iter 191616, Minibatch Loss= 48.940742, Training Accuracy= 0.98438\n",
      "1498\n",
      "Iter 191744, Minibatch Loss= 33.726093, Training Accuracy= 0.97656\n",
      "1499\n",
      "Iter 191872, Minibatch Loss= 118.861908, Training Accuracy= 0.98438\n",
      "1500\n",
      "Iter 192000, Minibatch Loss= 450.438110, Training Accuracy= 0.95312\n",
      "1501\n",
      "Iter 192128, Minibatch Loss= 182.622635, Training Accuracy= 0.96875\n",
      "1502\n",
      "Iter 192256, Minibatch Loss= 156.645889, Training Accuracy= 0.94531\n",
      "1503\n",
      "Iter 192384, Minibatch Loss= 269.346008, Training Accuracy= 0.96875\n",
      "1504\n",
      "Iter 192512, Minibatch Loss= 44.495621, Training Accuracy= 0.98438\n",
      "1505\n",
      "Iter 192640, Minibatch Loss= 38.277931, Training Accuracy= 0.98438\n",
      "1506\n",
      "Iter 192768, Minibatch Loss= 196.202347, Training Accuracy= 0.96875\n",
      "1507\n",
      "Iter 192896, Minibatch Loss= 96.034615, Training Accuracy= 0.97656\n",
      "1508\n",
      "Iter 193024, Minibatch Loss= 193.017883, Training Accuracy= 0.96875\n",
      "1509\n",
      "Iter 193152, Minibatch Loss= 23.098953, Training Accuracy= 0.99219\n",
      "1510\n",
      "Iter 193280, Minibatch Loss= 64.625275, Training Accuracy= 0.97656\n",
      "1511\n",
      "Iter 193408, Minibatch Loss= 123.089539, Training Accuracy= 0.98438\n",
      "1512\n",
      "Iter 193536, Minibatch Loss= 54.905060, Training Accuracy= 0.99219\n",
      "1513\n",
      "Iter 193664, Minibatch Loss= 261.669067, Training Accuracy= 0.95312\n",
      "1514\n",
      "Iter 193792, Minibatch Loss= 365.401733, Training Accuracy= 0.94531\n",
      "1515\n",
      "Iter 193920, Minibatch Loss= 110.872498, Training Accuracy= 0.97656\n",
      "1516\n",
      "Iter 194048, Minibatch Loss= 67.119148, Training Accuracy= 0.99219\n",
      "1517\n",
      "Iter 194176, Minibatch Loss= 59.317719, Training Accuracy= 0.99219\n",
      "1518\n",
      "Iter 194304, Minibatch Loss= 358.196289, Training Accuracy= 0.96094\n",
      "1519\n",
      "Iter 194432, Minibatch Loss= 155.346695, Training Accuracy= 0.97656\n",
      "1520\n",
      "Iter 194560, Minibatch Loss= 178.770142, Training Accuracy= 0.97656\n",
      "1521\n",
      "Iter 194688, Minibatch Loss= 353.730591, Training Accuracy= 0.96094\n",
      "1522\n",
      "Iter 194816, Minibatch Loss= 11.629868, Training Accuracy= 0.98438\n",
      "1523\n",
      "Iter 194944, Minibatch Loss= 305.475983, Training Accuracy= 0.95312\n",
      "1524\n",
      "Iter 195072, Minibatch Loss= 175.593262, Training Accuracy= 0.94531\n",
      "1525\n",
      "Iter 195200, Minibatch Loss= 79.240761, Training Accuracy= 0.97656\n",
      "1526\n",
      "Iter 195328, Minibatch Loss= 219.616791, Training Accuracy= 0.96875\n",
      "1527\n",
      "Iter 195456, Minibatch Loss= 55.737793, Training Accuracy= 0.98438\n",
      "1528\n",
      "Iter 195584, Minibatch Loss= 152.436523, Training Accuracy= 0.96875\n",
      "1529\n",
      "Iter 195712, Minibatch Loss= 304.855103, Training Accuracy= 0.96875\n",
      "1530\n",
      "Iter 195840, Minibatch Loss= 360.350677, Training Accuracy= 0.94531\n",
      "1531\n",
      "Iter 195968, Minibatch Loss= 96.473427, Training Accuracy= 0.98438\n",
      "1532\n",
      "Iter 196096, Minibatch Loss= 133.339615, Training Accuracy= 0.97656\n",
      "1533\n",
      "Iter 196224, Minibatch Loss= 84.007324, Training Accuracy= 0.97656\n",
      "1534\n",
      "Iter 196352, Minibatch Loss= 332.606018, Training Accuracy= 0.96094\n",
      "1535\n",
      "Iter 196480, Minibatch Loss= 145.791199, Training Accuracy= 0.97656\n",
      "1536\n",
      "Iter 196608, Minibatch Loss= 71.066536, Training Accuracy= 0.98438\n",
      "1537\n",
      "Iter 196736, Minibatch Loss= 97.409210, Training Accuracy= 0.96875\n",
      "1538\n",
      "Iter 196864, Minibatch Loss= 197.747513, Training Accuracy= 0.94531\n",
      "1539\n",
      "Iter 196992, Minibatch Loss= 585.561096, Training Accuracy= 0.96094\n",
      "1540\n",
      "Iter 197120, Minibatch Loss= 74.949570, Training Accuracy= 0.98438\n",
      "1541\n",
      "Iter 197248, Minibatch Loss= 151.452713, Training Accuracy= 0.96094\n",
      "1542\n",
      "Iter 197376, Minibatch Loss= 21.595474, Training Accuracy= 0.98438\n",
      "1543\n",
      "Iter 197504, Minibatch Loss= 186.909775, Training Accuracy= 0.96875\n",
      "1544\n",
      "Iter 197632, Minibatch Loss= 57.738770, Training Accuracy= 0.98438\n",
      "1545\n",
      "Iter 197760, Minibatch Loss= 147.556122, Training Accuracy= 0.96875\n",
      "1546\n",
      "Iter 197888, Minibatch Loss= 106.926476, Training Accuracy= 0.97656\n",
      "1547\n",
      "Iter 198016, Minibatch Loss= 442.366425, Training Accuracy= 0.92969\n",
      "1548\n",
      "Iter 198144, Minibatch Loss= 159.947937, Training Accuracy= 0.99219\n",
      "1549\n",
      "Iter 198272, Minibatch Loss= 164.316818, Training Accuracy= 0.97656\n",
      "1550\n",
      "Iter 198400, Minibatch Loss= 178.275497, Training Accuracy= 0.96875\n",
      "1551\n",
      "Iter 198528, Minibatch Loss= 32.047066, Training Accuracy= 0.97656\n",
      "1552\n",
      "Iter 198656, Minibatch Loss= 29.566162, Training Accuracy= 0.97656\n",
      "1553\n",
      "Iter 198784, Minibatch Loss= 105.141846, Training Accuracy= 0.97656\n",
      "1554\n",
      "Iter 198912, Minibatch Loss= 203.132889, Training Accuracy= 0.96094\n",
      "1555\n",
      "Iter 199040, Minibatch Loss= 202.227020, Training Accuracy= 0.96875\n",
      "1556\n",
      "Iter 199168, Minibatch Loss= 90.920433, Training Accuracy= 0.97656\n",
      "1557\n",
      "Iter 199296, Minibatch Loss= 359.140198, Training Accuracy= 0.96875\n",
      "1558\n",
      "Iter 199424, Minibatch Loss= 112.220322, Training Accuracy= 0.96875\n",
      "1559\n",
      "Iter 199552, Minibatch Loss= 16.869247, Training Accuracy= 0.99219\n",
      "1560\n",
      "Iter 199680, Minibatch Loss= 151.892532, Training Accuracy= 0.97656\n",
      "1561\n",
      "Iter 199808, Minibatch Loss= 258.399353, Training Accuracy= 0.93750\n",
      "1562\n",
      "Iter 199936, Minibatch Loss= 4.540558, Training Accuracy= 0.99219\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.988281\n"
     ]
    }
   ],
   "source": [
    "# convolutional neural networks\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)\n",
    "\n",
    "## parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 200000\n",
    "batch_size = 128\n",
    "\n",
    "## network parameters\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "dropout_rate = 0.8\n",
    "\n",
    "## tf graph input\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "## weights\n",
    "weights = {\n",
    "    ### convolutional layer 1 - 5*5 convolutional window, 1 input, 32 outputs\n",
    "    'wc1' : tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    ### convolutional layer 2 - 5*5 convolutional window, 32 inputs, 64 outputs\n",
    "    'wc2' : tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    ### fully connected layer - 7*7*64 inputs, 1024 outputs\n",
    "    'wd1' : tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    ### output layer - 1024 inputs, 10 output classes\n",
    "    'out' : tf.Variable(tf.random_normal([1024, 10]))\n",
    "}\n",
    "\n",
    "## biases\n",
    "biases = {\n",
    "    'bc1' : tf.Variable(tf.random_normal([32])),\n",
    "    'bc2' : tf.Variable(tf.random_normal([64])),\n",
    "    'bd1' : tf.Variable(tf.random_normal([1024])),\n",
    "    'out' : tf.Variable(tf.random_normal([10]))\n",
    "}\n",
    "\n",
    "def conv2d(x, w, b, strides = 1):\n",
    "    x = tf.nn.conv2d(x, w, strides = [1, strides, strides, 1], padding = 'SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    x = tf.nn.relu(x)\n",
    "    return(x)\n",
    "\n",
    "def maxpool2d(x, k = 2):\n",
    "    return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = 'SAME')\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    x = tf.reshape(x, shape = [-1, 28, 28, 1])\n",
    "\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    \n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "    \n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "pred = conv_net(X, weights, biases, keep_prob)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    while step * batch_size < training_epochs:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer, feed_dict={X: batch_x, y: batch_y, keep_prob: dropout_rate})\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={X: batch_x, y: batch_y, keep_prob: 1.})\n",
    "        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={X: mnist.test.images[:256], y: mnist.test.labels[:256], keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
